{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FYdqqSbxymLp",
    "outputId": "a3bd2cb5-32c6-4c00-8cd3-2752db3e8e80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spectral in /home/mengao/.local/lib/python3.9/site-packages (0.23.1)\n",
      "Requirement already satisfied: numpy in /usr/local/anaconda3/lib/python3.9/site-packages (from spectral) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "AEVP6x5CviqP",
    "outputId": "32d5b6cb-ecf7-4000-e68d-a4d2ac0398f8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.20.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, Conv3D, Flatten, Dense, Reshape, BatchNormalization\n",
    "from keras.layers import Dropout, Input\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
    "\n",
    "from operator import truediv\n",
    "\n",
    "from plotly.offline import init_notebook_mode\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import spectral\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "msb54AxTvsxl",
    "outputId": "edf5dfab-df9a-4825-acd2-eca512202d5b"
   },
   "outputs": [],
   "source": [
    "if not (os.path.isfile('Indian_pines_corrected.mat')):\n",
    "  !wget http://www.ehu.eus/ccwintco/uploads/6/67/Indian_pines_corrected.mat\n",
    "if not (os.path.isfile('Indian_pines_gt.mat')):\n",
    "  !wget http://www.ehu.eus/ccwintco/uploads/c/c4/Indian_pines_gt.mat\n",
    "\n",
    "#if not (os.path.isfile('/content/Salinas_corrected.mat')):\n",
    "#  !wget https://github.com/gokriznastic/HybridSN/raw/master/data/Salinas_corrected.mat\n",
    "#if not (os.path.isfile('/content/Salinas_gt.mat')):\n",
    "#  !wget https://github.com/gokriznastic/HybridSN/raw/master/data/Salinas_gt.mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0dGKcU9viqk"
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "taV2QK36viqm"
   },
   "outputs": [],
   "source": [
    "## GLOBAL VARIABLES\n",
    "dataset = 'PU'\n",
    "test_ratio = 0.5\n",
    "windowSize = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "c2S9wEYaviq3"
   },
   "outputs": [],
   "source": [
    "def loadData(name):\n",
    "    data_path = os.path.join(os.getcwd(),'data')\n",
    "    if name == 'IP':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'Indian_pines_corrected.mat'))['indian_pines_corrected']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'Indian_pines_gt.mat'))['indian_pines_gt']\n",
    "    elif name == 'SA':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'Salinas_corrected.mat'))['salinas_corrected']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'Salinas_gt.mat'))['salinas_gt']\n",
    "    elif name == 'PU':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'PaviaU.mat'))['paviaU']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'PaviaU_gt.mat'))['paviaU_gt']\n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2u6ACykXvirD"
   },
   "outputs": [],
   "source": [
    "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState,\n",
    "                                                        stratify=y)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fN58ewFGvirP"
   },
   "outputs": [],
   "source": [
    "def applyPCA(X, numComponents=75):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    pca = PCA(n_components=numComponents, whiten=True)\n",
    "    newX = pca.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
    "    return newX, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Taj-YwjLvirZ"
   },
   "outputs": [],
   "source": [
    "def padWithZeros(X, margin=2):\n",
    "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
    "    x_offset = margin\n",
    "    y_offset = margin\n",
    "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
    "    return newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VMotOvASvirk"
   },
   "outputs": [],
   "source": [
    "def createImageCubes(X, y, windowSize=5, removeZeroLabels = True):\n",
    "    margin = int((windowSize - 1) / 2)\n",
    "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
    "    # split patches\n",
    "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
    "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
    "    patchIndex = 0\n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]   \n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
    "            patchIndex = patchIndex + 1\n",
    "    if removeZeroLabels:\n",
    "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
    "        patchesLabels = patchesLabels[patchesLabels>0]\n",
    "        patchesLabels -= 1\n",
    "    return patchesData, patchesLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WA1HHQR2virt",
    "outputId": "b6254096-fb23-4c9e-b676-dad4e14de6b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((610, 340, 103), (610, 340))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = loadData(dataset)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-t05nhFGvir0"
   },
   "outputs": [],
   "source": [
    "K = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fLnJhFgZvir-",
    "outputId": "91aca617-9961-4507-eda9-a9463e706fb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 340, 15)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 30 if dataset == 'IP' else 15\n",
    "X,pca = applyPCA(X,numComponents=K)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5VY0zJh-visG",
    "outputId": "0c921785-bd38-4c78-ae5c-0e20d855266a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42776, 25, 25, 15), (42776,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = createImageCubes(X, y, windowSize=windowSize)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IHfhGxoxvisQ",
    "outputId": "2dc92fa4-3fca-4a69-999f-c1231d5e2ff2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21388, 25, 25, 15), (21388, 25, 25, 15), (21388,), (21388,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = splitTrainTestSet(X, y, test_ratio)\n",
    "\n",
    "Xtrain.shape, Xtest.shape, ytrain.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DYJ7vX5visa"
   },
   "source": [
    "Xtrain, Xvalid, ytrain, yvalid = splitTrainTestSet(Xtrain, ytrain, 0.3333)\n",
    "\n",
    "Xtrain.shape, Xvalid.shape, ytrain.shape, yvalid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImXShO0dvisc"
   },
   "source": [
    "# Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IoNjNFA_vise",
    "outputId": "756f878d-86ba-4089-d8dc-156b6a6eac4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21388, 25, 25, 15, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = Xtrain.reshape(-1, windowSize, windowSize, K, 1)\n",
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7G1kSqbgvism",
    "outputId": "f2c0955f-55a9-4ece-cc5b-5fb307f81051"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21388, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain = np_utils.to_categorical(ytrain)\n",
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vrezb-7Rvisu"
   },
   "source": [
    "Xvalid = Xvalid.reshape(-1, windowSize, windowSize, K, 1)\n",
    "Xvalid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dGLRXMMvisx"
   },
   "source": [
    "yvalid = np_utils.to_categorical(yvalid)\n",
    "yvalid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "aNz8CNqYvisz"
   },
   "outputs": [],
   "source": [
    "S = windowSize\n",
    "L = K\n",
    "output_units = 9 if (dataset == 'PU' or dataset == 'PC') else 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "uEecMnQYvis6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 22:35:34.815678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 22:35:34.862738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 22:35:34.863037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 22:35:34.889446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 22:35:34.890001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 22:35:34.890484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 22:35:35.803589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 22:35:35.803873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 22:35:35.804085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 22:35:35.804278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11428 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:02:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "## input layer\n",
    "input_layer = Input((S, S, L, 1))\n",
    "\n",
    "## convolutional layers\n",
    "conv_layer1 = Conv3D(filters=8, kernel_size=(3, 3, 7), activation='relu')(input_layer)\n",
    "conv_layer2 = Conv3D(filters=16, kernel_size=(3, 3, 5), activation='relu')(conv_layer1)\n",
    "conv_layer3 = Conv3D(filters=32, kernel_size=(3, 3, 3), activation='relu')(conv_layer2)\n",
    "#print(conv_layer3._keras_shape)\n",
    "conv3d_shape = conv_layer3.shape\n",
    "conv_layer3 = Reshape((conv3d_shape[1], conv3d_shape[2], conv3d_shape[3]*conv3d_shape[4]))(conv_layer3)\n",
    "conv_layer4 = Conv2D(filters=64, kernel_size=(3,3), activation='relu')(conv_layer3)\n",
    "\n",
    "flatten_layer = Flatten()(conv_layer4)\n",
    "\n",
    "## fully connected layers\n",
    "dense_layer1 = Dense(units=256, activation='relu')(flatten_layer)\n",
    "dense_layer1 = Dropout(0.4)(dense_layer1)\n",
    "dense_layer2 = Dense(units=128, activation='relu')(dense_layer1)\n",
    "dense_layer2 = Dropout(0.4)(dense_layer2)\n",
    "output_layer = Dense(units=output_units, activation='softmax')(dense_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "X_jkfy0evitB"
   },
   "outputs": [],
   "source": [
    "# define the model with input layer and output layer\n",
    "model = Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aMDUyRiivitH",
    "outputId": "5d0ec41b-525c-4727-9cc7-d4ac6d4aa67c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 25, 25, 15, 1)]   0         \n",
      "                                                                 \n",
      " conv3d (Conv3D)             (None, 23, 23, 9, 8)      512       \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 21, 21, 5, 16)     5776      \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 19, 19, 3, 32)     13856     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 19, 19, 96)        0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 17, 17, 64)        55360     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18496)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               4735232   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,844,793\n",
      "Trainable params: 4,844,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "KEfKakAjvitN"
   },
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "adam = Adam(learning_rate=0.001, decay=1e-06)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ddDzXAfUvitU"
   },
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "filepath = \"best-model.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ENyt1ex5vitc",
    "outputId": "a5c3e08e-876b-44d8-f056-9b240bbbc95b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 22:35:41.255637: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8500\n",
      "2023-05-15 22:35:42.062421: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-15 22:35:42.193522: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - ETA: 0s - loss: 0.4413 - accuracy: 0.8501WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 7s 18ms/step - loss: 0.4413 - accuracy: 0.8501\n",
      "Epoch 2/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0330 - accuracy: 0.9909WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0330 - accuracy: 0.9909\n",
      "Epoch 3/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9949WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0191 - accuracy: 0.9949\n",
      "Epoch 4/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9962WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.0145 - accuracy: 0.9962\n",
      "Epoch 5/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9985WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0053 - accuracy: 0.9985\n",
      "Epoch 6/100\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.9921WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0317 - accuracy: 0.9921\n",
      "Epoch 7/100\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9977WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0110 - accuracy: 0.9977\n",
      "Epoch 8/100\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.0167 - accuracy: 0.9961WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0167 - accuracy: 0.9961\n",
      "Epoch 9/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9982WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0068 - accuracy: 0.9982\n",
      "Epoch 10/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 11/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9976WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0103 - accuracy: 0.9976\n",
      "Epoch 12/100\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9991WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0021 - accuracy: 0.9991\n",
      "Epoch 13/100\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.0356 - accuracy: 0.9938WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0353 - accuracy: 0.9938\n",
      "Epoch 14/100\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9982WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0072 - accuracy: 0.9982\n",
      "Epoch 15/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9992WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 19ms/step - loss: 0.0046 - accuracy: 0.9992\n",
      "Epoch 16/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9996WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0019 - accuracy: 0.9996\n",
      "Epoch 17/100\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.0157 - accuracy: 0.9971WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0157 - accuracy: 0.9971\n",
      "Epoch 18/100\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9988WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0067 - accuracy: 0.9988\n",
      "Epoch 19/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 20/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9991WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0043 - accuracy: 0.9991\n",
      "Epoch 21/100\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9963WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 19ms/step - loss: 0.0323 - accuracy: 0.9963\n",
      "Epoch 22/100\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.0324 - accuracy: 0.9946WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0326 - accuracy: 0.9946\n",
      "Epoch 23/100\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.0624 - accuracy: 0.9914WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0617 - accuracy: 0.9915\n",
      "Epoch 24/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9990WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0042 - accuracy: 0.9990\n",
      "Epoch 25/100\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9997WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0017 - accuracy: 0.9997\n",
      "Epoch 26/100\n",
      "168/168 [==============================] - ETA: 0s - loss: 9.2765e-04 - accuracy: 0.9996WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 9.2765e-04 - accuracy: 0.9996\n",
      "Epoch 27/100\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9998WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0032 - accuracy: 0.9998\n",
      "Epoch 28/100\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 29/100\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 30/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9993WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 31/100\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9993WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 32/100\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9996WARNING:tensorflow:Can save best model only with acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0029 - accuracy: 0.9996\n",
      "Epoch 33/100\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9994WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0043 - accuracy: 0.9994\n",
      "Epoch 34/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9997WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9997\n",
      "Epoch 35/100\n",
      "167/168 [============================>.] - ETA: 0s - loss: 9.6624e-04 - accuracy: 0.9998WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 9.6570e-04 - accuracy: 0.9998\n",
      "Epoch 36/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9982WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0143 - accuracy: 0.9982\n",
      "Epoch 37/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0274 - accuracy: 0.9959WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0283 - accuracy: 0.9957\n",
      "Epoch 38/100\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.0179 - accuracy: 0.9976WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0179 - accuracy: 0.9976\n",
      "Epoch 39/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9979WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.0134 - accuracy: 0.9979\n",
      "Epoch 40/100\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9987WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0067 - accuracy: 0.9987\n",
      "Epoch 41/100\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9989WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.0082 - accuracy: 0.9989\n",
      "Epoch 42/100\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9983WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.0134 - accuracy: 0.9983\n",
      "Epoch 43/100\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.0139 - accuracy: 0.9987WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0137 - accuracy: 0.9987\n",
      "Epoch 44/100\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9989WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.0062 - accuracy: 0.9989\n",
      "Epoch 45/100\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.9976WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0285 - accuracy: 0.9976\n",
      "Epoch 46/100\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.9988WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0094 - accuracy: 0.9988\n",
      "Epoch 47/100\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9985WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0137 - accuracy: 0.9985\n",
      "Epoch 48/100\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9994WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0037 - accuracy: 0.9994\n",
      "Epoch 49/100\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9999WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0011 - accuracy: 0.9999\n",
      "Epoch 50/100\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9997WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 51/100\n",
      "168/168 [==============================] - ETA: 0s - loss: 3.4160e-04 - accuracy: 0.9999WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 3.4160e-04 - accuracy: 0.9999\n",
      "Epoch 52/100\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9999WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9999\n",
      "Epoch 53/100\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9998WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0077 - accuracy: 0.9998\n",
      "Epoch 54/100\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9991WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0061 - accuracy: 0.9991\n",
      "Epoch 55/100\n",
      "165/168 [============================>.] - ETA: 0s - loss: 7.8926e-04 - accuracy: 0.9998WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 7.7937e-04 - accuracy: 0.9998\n",
      "Epoch 56/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9993WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0081 - accuracy: 0.9993\n",
      "Epoch 57/100\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9982WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.0191 - accuracy: 0.9982\n",
      "Epoch 58/100\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9982WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0144 - accuracy: 0.9982\n",
      "Epoch 59/100\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9994WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.0032 - accuracy: 0.9994\n",
      "Epoch 60/100\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9993WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0065 - accuracy: 0.9993\n",
      "Epoch 61/100\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9994WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0050 - accuracy: 0.9994\n",
      "Epoch 62/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9992WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0060 - accuracy: 0.9992\n",
      "Epoch 63/100\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.0232 - accuracy: 0.9983WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0229 - accuracy: 0.9984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9994WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0037 - accuracy: 0.9994\n",
      "Epoch 65/100\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9996WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0038 - accuracy: 0.9996\n",
      "Epoch 66/100\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9993WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0070 - accuracy: 0.9993\n",
      "Epoch 67/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9994WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0043 - accuracy: 0.9994\n",
      "Epoch 68/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0117 - accuracy: 0.9992WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0117 - accuracy: 0.9992\n",
      "Epoch 69/100\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9973WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0286 - accuracy: 0.9973\n",
      "Epoch 70/100\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9990WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0151 - accuracy: 0.9990\n",
      "Epoch 71/100\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9991WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0092 - accuracy: 0.9991\n",
      "Epoch 72/100\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9998WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0016 - accuracy: 0.9998\n",
      "Epoch 73/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9995WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0081 - accuracy: 0.9995\n",
      "Epoch 74/100\n",
      "167/168 [============================>.] - ETA: 0s - loss: 3.9294e-04 - accuracy: 0.9998WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 3.9272e-04 - accuracy: 0.9998\n",
      "Epoch 75/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9996WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0074 - accuracy: 0.9996\n",
      "Epoch 76/100\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9991WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0168 - accuracy: 0.9991\n",
      "Epoch 77/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.9988WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0176 - accuracy: 0.9988\n",
      "Epoch 78/100\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9997WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0056 - accuracy: 0.9997\n",
      "Epoch 79/100\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.9986WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0179 - accuracy: 0.9986\n",
      "Epoch 80/100\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9996WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.0052 - accuracy: 0.9996\n",
      "Epoch 81/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9999    WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.0029 - accuracy: 0.9999\n",
      "Epoch 82/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9991WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0105 - accuracy: 0.9991\n",
      "Epoch 83/100\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9995WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0040 - accuracy: 0.9995\n",
      "Epoch 84/100\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9998WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0033 - accuracy: 0.9998\n",
      "Epoch 85/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9996WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.0063 - accuracy: 0.9996\n",
      "Epoch 86/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9996WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0045 - accuracy: 0.9996\n",
      "Epoch 87/100\n",
      "165/168 [============================>.] - ETA: 0s - loss: 7.9233e-04 - accuracy: 0.9999WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 7.8241e-04 - accuracy: 0.9999\n",
      "Epoch 88/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9997WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.0036 - accuracy: 0.9997\n",
      "Epoch 89/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9989WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0151 - accuracy: 0.9989\n",
      "Epoch 90/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0258 - accuracy: 0.9980WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0256 - accuracy: 0.9980\n",
      "Epoch 91/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0222 - accuracy: 0.9988WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0236 - accuracy: 0.9988\n",
      "Epoch 92/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0403 - accuracy: 0.9975WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0400 - accuracy: 0.9975\n",
      "Epoch 93/100\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9996WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0057 - accuracy: 0.9996\n",
      "Epoch 94/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9997WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/168 [============================>.] - ETA: 0s - loss: 1.7684e-04 - accuracy: 0.9999WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 1.7674e-04 - accuracy: 0.9999\n",
      "Epoch 96/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9998WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 18ms/step - loss: 0.0047 - accuracy: 0.9998\n",
      "Epoch 97/100\n",
      "165/168 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9994WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 16ms/step - loss: 0.0102 - accuracy: 0.9993\n",
      "Epoch 98/100\n",
      "166/168 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9997WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0065 - accuracy: 0.9997\n",
      "Epoch 99/100\n",
      "168/168 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9995WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0068 - accuracy: 0.9995\n",
      "Epoch 100/100\n",
      "167/168 [============================>.] - ETA: 0s - loss: 0.0296 - accuracy: 0.9986WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "168/168 [==============================] - 3s 17ms/step - loss: 0.0296 - accuracy: 0.9986\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=Xtrain, y=ytrain, batch_size=128, epochs=100, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "PfSP_f8ywJR1"
   },
   "outputs": [],
   "source": [
    "model.save(\"best-model.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wg3XlImlvitn"
   },
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "GKH6QFcmvitp"
   },
   "outputs": [],
   "source": [
    "# load best weights\n",
    "model.load_weights(\"best-model.hdf5\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "6ynlGSBkvitv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21388, 25, 25, 15, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest = Xtest.reshape(-1, windowSize, windowSize, K, 1)\n",
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "FrQBCdrqvit3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21388, 9)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest = np_utils.to_categorical(ytest)\n",
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ZDidpOOjvit-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3316\n",
      "           1       1.00      1.00      1.00      9324\n",
      "           2       1.00      1.00      1.00      1049\n",
      "           3       1.00      1.00      1.00      1532\n",
      "           4       1.00      1.00      1.00       673\n",
      "           5       1.00      1.00      1.00      2514\n",
      "           6       1.00      1.00      1.00       665\n",
      "           7       1.00      1.00      1.00      1841\n",
      "           8       1.00      1.00      1.00       474\n",
      "\n",
      "    accuracy                           1.00     21388\n",
      "   macro avg       1.00      1.00      1.00     21388\n",
      "weighted avg       1.00      1.00      1.00     21388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred_test = model.predict(Xtest)\n",
    "y_pred_test = np.argmax(Y_pred_test, axis=1)\n",
    "\n",
    "classification = classification_report(np.argmax(ytest, axis=1), y_pred_test)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "fY39UA0nviuG"
   },
   "outputs": [],
   "source": [
    "def AA_andEachClassAccuracy(confusion_matrix):\n",
    "    counter = confusion_matrix.shape[0]\n",
    "    list_diag = np.diag(confusion_matrix)\n",
    "    list_raw_sum = np.sum(confusion_matrix, axis=1)\n",
    "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
    "    average_acc = np.mean(each_acc)\n",
    "    return each_acc, average_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "_rNFvCZDviuM"
   },
   "outputs": [],
   "source": [
    "def reports (X_test,y_test,name):\n",
    "    #start = time.time()\n",
    "    Y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    #end = time.time()\n",
    "    #print(end - start)\n",
    "    if name == 'IP':\n",
    "        target_names = ['Alfalfa', 'Corn-notill', 'Corn-mintill', 'Corn'\n",
    "                        ,'Grass-pasture', 'Grass-trees', 'Grass-pasture-mowed', \n",
    "                        'Hay-windrowed', 'Oats', 'Soybean-notill', 'Soybean-mintill',\n",
    "                        'Soybean-clean', 'Wheat', 'Woods', 'Buildings-Grass-Trees-Drives',\n",
    "                        'Stone-Steel-Towers']\n",
    "    elif name == 'SA':\n",
    "        target_names = ['Brocoli_green_weeds_1','Brocoli_green_weeds_2','Fallow','Fallow_rough_plow','Fallow_smooth',\n",
    "                        'Stubble','Celery','Grapes_untrained','Soil_vinyard_develop','Corn_senesced_green_weeds',\n",
    "                        'Lettuce_romaine_4wk','Lettuce_romaine_5wk','Lettuce_romaine_6wk','Lettuce_romaine_7wk',\n",
    "                        'Vinyard_untrained','Vinyard_vertical_trellis']\n",
    "    elif name == 'PU':\n",
    "        target_names = ['Asphalt','Meadows','Gravel','Trees', 'Painted metal sheets','Bare Soil','Bitumen',\n",
    "                        'Self-Blocking Bricks','Shadows']\n",
    "    \n",
    "    classification = classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names)\n",
    "    oa = accuracy_score(np.argmax(y_test, axis=1), y_pred)\n",
    "    confusion = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
    "    each_acc, aa = AA_andEachClassAccuracy(confusion)\n",
    "    kappa = cohen_kappa_score(np.argmax(y_test, axis=1), y_pred)\n",
    "    score = model.evaluate(X_test, y_test, batch_size=32)\n",
    "    Test_Loss =  score[0]*100\n",
    "    Test_accuracy = score[1]*100\n",
    "    \n",
    "    return classification, confusion, Test_Loss, Test_accuracy, oa*100, each_acc*100, aa*100, kappa*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "O6eDf1WHviuS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669/669 [==============================] - 5s 7ms/step - loss: 0.0135 - accuracy: 0.9996\n"
     ]
    }
   ],
   "source": [
    "classification, confusion, Test_loss, Test_accuracy, oa, each_acc, aa, kappa = reports(Xtest,ytest,dataset)\n",
    "classification = str(classification)\n",
    "confusion = str(confusion)\n",
    "file_name = \"classification_report_PU.txt\"\n",
    "\n",
    "with open(file_name, 'w') as x_file:\n",
    "    x_file.write('{} Test loss (%)'.format(Test_loss))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Test accuracy (%)'.format(Test_accuracy))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Kappa accuracy (%)'.format(kappa))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Overall accuracy (%)'.format(oa))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Average accuracy (%)'.format(aa))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{}'.format(classification))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{}'.format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "bftzj-2_viuY"
   },
   "outputs": [],
   "source": [
    "def Patch(data,height_index,width_index):\n",
    "    height_slice = slice(height_index, height_index+PATCH_SIZE)\n",
    "    width_slice = slice(width_index, width_index+PATCH_SIZE)\n",
    "    patch = data[height_slice, width_slice, :]\n",
    "    \n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "dBWs8kmzviue"
   },
   "outputs": [],
   "source": [
    "# load the original image\n",
    "X, y = loadData(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "cFsdbo9Aviuk"
   },
   "outputs": [],
   "source": [
    "height = y.shape[0]\n",
    "width = y.shape[1]\n",
    "PATCH_SIZE = windowSize\n",
    "numComponents = K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "J9dc-buXviup"
   },
   "outputs": [],
   "source": [
    "X,pca = applyPCA(X, numComponents=numComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Eq14Gv4rvius"
   },
   "outputs": [],
   "source": [
    "X = padWithZeros(X, PATCH_SIZE//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "yBtYMNhWviu0"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m image_patch\u001b[38;5;241m=\u001b[39mPatch(X,i,j)\n\u001b[1;32m     10\u001b[0m X_test_image \u001b[38;5;241m=\u001b[39m image_patch\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,image_patch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],image_patch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], image_patch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)                                   \n\u001b[0;32m---> 11\u001b[0m prediction \u001b[38;5;241m=\u001b[39m (\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_image\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     12\u001b[0m prediction \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(prediction, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m outputs[i][j] \u001b[38;5;241m=\u001b[39m prediction\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/keras/engine/training.py:1758\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1750\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m   1751\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1752\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsing Model.predict with \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1753\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultiWorkerDistributionStrategy or TPUStrategy and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1754\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoShardPolicy.FILE might lead to out-of-order result\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Consider setting it to AutoShardPolicy.DATA.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1756\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m-> 1758\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1759\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1760\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1761\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1762\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1763\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1764\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1767\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1768\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1770\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   1771\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/keras/engine/data_adapter.py:1403\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1402\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/keras/engine/data_adapter.py:1153\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1150\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[1;32m   1152\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1167\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/keras/engine/data_adapter.py:291\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m indices\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# We prefetch a single element. Computing large permutations can take quite\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# a while so we don't want to wait for prefetching over an epoch boundary to\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# trigger the next permutation. On the other hand, too many simultaneous\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# shuffles can contend on a hardware level and degrade all performance.\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mindices_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpermutation\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mprefetch(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mslice_batch_indices\u001b[39m(indices):\n\u001b[1;32m    294\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Convert a Tensor of indices into a dataset of batched indices.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m  This step can be accomplished in several ways. The most natural is to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;124;03m    A Dataset of batched indices.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:2004\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2001\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m DEBUG_MODE:\n\u001b[1;32m   2002\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2003\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2004\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2006\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[1;32m   2007\u001b[0m       \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2008\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2011\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2012\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:5455\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m   5454\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[0;32m-> 5455\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5457\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5459\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5460\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata \u001b[38;5;241m=\u001b[39m dataset_metadata_pb2\u001b[38;5;241m.\u001b[39mMetadata()\n\u001b[1;32m   5461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name:\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:4533\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   4526\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   4527\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4528\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4529\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4530\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4531\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m-> 4533\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4534\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m   4535\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3244\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3236\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m   3237\u001b[0m \n\u001b[1;32m   3238\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3242\u001b[0m \u001b[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m   3243\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3244\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3245\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3246\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   3247\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3210\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3208\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3209\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 3210\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3211\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m   3212\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[1;32m   3213\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3557\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3553\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3554\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3556\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[0;32m-> 3557\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3558\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[1;32m   3560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3392\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3387\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3388\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3389\u001b[0m ]\n\u001b[1;32m   3390\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3391\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3392\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3393\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3394\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3395\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3397\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3400\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3401\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3403\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3404\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3405\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3406\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3407\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3408\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3409\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1143\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1141\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1143\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m   1148\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:4510\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   4504\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[1;32m   4505\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[1;32m   4506\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[1;32m   4507\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   4508\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[1;32m   4509\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m-> 4510\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4511\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m   4512\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:4440\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   4438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m   4439\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m-> 4440\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n\u001b[1;32m   4442\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ret)\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:696\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 696\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    698\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:383\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 383\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:464\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    461\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/keras/engine/data_adapter.py:282\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__.<locals>.permutation\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpermutation\u001b[39m(_):\n\u001b[1;32m    279\u001b[0m   \u001b[38;5;66;03m# It turns out to be more performant to make a new set of indices rather\u001b[39;00m\n\u001b[1;32m    280\u001b[0m   \u001b[38;5;66;03m# than reusing the same range Tensor. (presumably because of buffer\u001b[39;00m\n\u001b[1;32m    281\u001b[0m   \u001b[38;5;66;03m# forwarding.)\u001b[39;00m\n\u001b[0;32m--> 282\u001b[0m   indices \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mand\u001b[39;00m shuffle \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    284\u001b[0m     indices \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(indices)\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1096\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1098\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:2104\u001b[0m, in \u001b[0;36mrange\u001b[0;34m(start, limit, delta, dtype, name)\u001b[0m\n\u001b[1;32m   2101\u001b[0m limit \u001b[38;5;241m=\u001b[39m cast(limit, inferred_dtype)\n\u001b[1;32m   2102\u001b[0m delta \u001b[38;5;241m=\u001b[39m cast(delta, inferred_dtype)\n\u001b[0;32m-> 2104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_math_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_range\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py:7746\u001b[0m, in \u001b[0;36m_range\u001b[0;34m(start, limit, delta, name)\u001b[0m\n\u001b[1;32m   7744\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m   7745\u001b[0m \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m-> 7746\u001b[0m _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_op_def_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   7747\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRange\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7748\u001b[0m _result \u001b[38;5;241m=\u001b[39m _outputs[:]\n\u001b[1;32m   7749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:744\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    739\u001b[0m must_colocate_inputs \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m arg, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(op_def\u001b[38;5;241m.\u001b[39minput_arg, inputs)\n\u001b[1;32m    740\u001b[0m                         \u001b[38;5;28;01mif\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mis_ref]\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[1;32m    742\u001b[0m   \u001b[38;5;66;03m# Add Op to graph\u001b[39;00m\n\u001b[1;32m    743\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 744\u001b[0m   op \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattr_protos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;66;03m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;66;03m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;66;03m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;66;03m# for more details.\u001b[39;00m\n\u001b[1;32m    752\u001b[0m outputs \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39moutputs\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:689\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    687\u001b[0m   inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapture(inp)\n\u001b[1;32m    688\u001b[0m   captured_inputs\u001b[38;5;241m.\u001b[39mappend(inp)\n\u001b[0;32m--> 689\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFuncGraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3690\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3687\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3688\u001b[0m   name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munique_name(name)\n\u001b[0;32m-> 3690\u001b[0m node_def \u001b[38;5;241m=\u001b[39m \u001b[43m_NodeDef\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3692\u001b[0m input_ops \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(t\u001b[38;5;241m.\u001b[39mop \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs)\n\u001b[1;32m   3693\u001b[0m control_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_control_dependencies_for_inputs(input_ops)\n",
      "File \u001b[0;32m/data/condashare/tf/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1876\u001b[0m, in \u001b[0;36m_NodeDef\u001b[0;34m(op_type, name, attrs)\u001b[0m\n\u001b[1;32m   1874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attrs:\n\u001b[1;32m   1875\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m six\u001b[38;5;241m.\u001b[39miteritems(attrs):\n\u001b[0;32m-> 1876\u001b[0m     \u001b[43mnode_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mCopyFrom(v)\n\u001b[1;32m   1877\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node_def\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# calculate the predicted image\n",
    "outputs = np.zeros((height,width))\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        target = int(y[i,j])\n",
    "        if target == 0 :\n",
    "            continue\n",
    "        else :\n",
    "            image_patch=Patch(X,i,j)\n",
    "            X_test_image = image_patch.reshape(1,image_patch.shape[0],image_patch.shape[1], image_patch.shape[2], 1).astype('float32')                                   \n",
    "            prediction = (model.predict(X_test_image))\n",
    "            prediction = np.argmax(prediction, axis=1)\n",
    "            outputs[i][j] = prediction+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2H_WBEHEviu5"
   },
   "outputs": [],
   "source": [
    "ground_truth = spectral.imshow(classes = y,figsize =(7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TIXpiUnavivA"
   },
   "outputs": [],
   "source": [
    "predict_image = spectral.imshow(classes = outputs.astype(int),figsize =(7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nqc0ygfYvivI"
   },
   "outputs": [],
   "source": [
    "spectral.save_rgb(\"predictions.jpg\", outputs.astype(int), colors=spectral.spy_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNgBjynzvivN"
   },
   "source": [
    "spectral.save_rgb(str(dataset)+\"_ground_truth.jpg\", y, colors=spectral.spy_colors)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ImXShO0dvisc",
    "wg3XlImlvitn"
   ],
   "name": "HybridSN_V1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpectralNET Exploring Spatial Spectral Wavelet CNN for Hyper Spectral Image Classification\n",
    "\n",
    "**Authors:** Tanmay CHAKRABORTY and Utkarsh TREHAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "executionInfo": {
     "elapsed": 5572,
     "status": "ok",
     "timestamp": 1602478409232,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "r9imWZNCMoOM",
    "outputId": "e6ddc3e2-53c3-4e29-ceb6-5b303ac0b75b"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, Conv3D, Flatten, Dense, Reshape, BatchNormalization, ReLU\n",
    "from tensorflow.keras.layers import Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.keras import backend as Kb\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.python.keras.layers.merge import add, concatenate\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "# from tensorflow.keras.utils.vis_utils import plot_model\n",
    "import tensorflow.keras.backend as backend\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
    " \n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from operator import truediv\n",
    " \n",
    "from plotly.offline import init_notebook_mode\n",
    " \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5565,
     "status": "ok",
     "timestamp": 1602478409233,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "HC83Bv1IPQfc"
   },
   "outputs": [],
   "source": [
    "def applyFA(X, numComponents=75):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    fa = FactorAnalysis(n_components=numComponents, random_state=0)\n",
    "    newX = fa.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
    "    return newX, fa\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5559,
     "status": "ok",
     "timestamp": 1602478409234,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "UGivdxXN1pCh"
   },
   "outputs": [],
   "source": [
    "# def applyPCA(X, numComponents=75):\n",
    "#     newX = np.reshape(X, (-1, X.shape[2]))\n",
    "#     pca = PCA(n_components=numComponents, whiten=True)\n",
    "#     newX = pca.fit_transform(newX)\n",
    "#     newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
    "#     return newX, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5555,
     "status": "ok",
     "timestamp": 1602478409235,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "jEBfhIyVNHRQ"
   },
   "outputs": [],
   "source": [
    "## GLOBAL VARIABLES\n",
    "dataset = 'SA'\n",
    "test_ratio = 0.5\n",
    "windowSize = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5550,
     "status": "ok",
     "timestamp": 1602478409236,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "7wXNSkhfM3gs"
   },
   "outputs": [],
   "source": [
    "def loadData(name):\n",
    "    data_path = os.path.join(os.getcwd(),'data')\n",
    "    if name == 'IP':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'Indian_pines_corrected.mat'))['indian_pines_corrected']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'Indian_pines_gt.mat'))['indian_pines_gt']\n",
    "    elif name == 'SA':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'Salinas_corrected.mat'))['salinas_corrected']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'Salinas_gt.mat'))['salinas_gt']\n",
    "    elif name == 'PU':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'PaviaU.mat'))['paviaU']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'PaviaU_gt.mat'))['paviaU_gt']\n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5545,
     "status": "ok",
     "timestamp": 1602478409237,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "iaIzfkQ3NDvS"
   },
   "outputs": [],
   "source": [
    "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState,\n",
    "                                                        stratify=y)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 5538,
     "status": "ok",
     "timestamp": 1602478409237,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "M0he4FtONMU-"
   },
   "outputs": [],
   "source": [
    "def padWithZeros(X, margin=2):\n",
    "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
    "    x_offset = margin\n",
    "    y_offset = margin\n",
    "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
    "    return newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 5533,
     "status": "ok",
     "timestamp": 1602478409238,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "l0wsTkhNNO04"
   },
   "outputs": [],
   "source": [
    "def createImageCubes(X, y, windowSize=8, removeZeroLabels = True):\n",
    "    margin = int((windowSize) / 2)\n",
    "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
    "    # split patches\n",
    "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
    "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
    "    patchIndex = 0\n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin:r + margin , c - margin:c + margin ]   \n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
    "            patchIndex = patchIndex + 1\n",
    "    if removeZeroLabels:\n",
    "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
    "        patchesLabels = patchesLabels[patchesLabels>0]\n",
    "        patchesLabels -= 1\n",
    "    return patchesData, patchesLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 5525,
     "status": "ok",
     "timestamp": 1602478409238,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "cnneGlFFNRVo",
    "outputId": "3b00138d-9d02-4b14-f6e2-2b1dc9ad8aeb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((145, 145, 200), (145, 145))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = loadData(dataset)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 5518,
     "status": "ok",
     "timestamp": 1602478409239,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "TOGl1BmWNdyv"
   },
   "outputs": [],
   "source": [
    "K = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 30165,
     "status": "ok",
     "timestamp": 1602478433894,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "fTYzjiltNj8a",
    "outputId": "7bfa99db-15b8-40d1-83b2-b7d32d039c0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 145, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 3 if dataset == 'IP' else 3\n",
    "X,fa = applyFA(X,numComponents=K)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 31758,
     "status": "ok",
     "timestamp": 1602478435499,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "hiZiDsE0cN-O",
    "outputId": "acf836b7-666b-4104-c856-d4e0b1d1f84f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10249, 32, 32, 3), (10249,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = createImageCubes(X, y, windowSize=windowSize)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 31739,
     "status": "ok",
     "timestamp": 1602478435500,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "OMYMZxnDcSHb",
    "outputId": "8e9b4564-aff1-40e2-b081-7154c18d5d77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5124, 32, 32, 3), (5125, 32, 32, 3), (5124,), (5125,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = splitTrainTestSet(X, y, test_ratio)\n",
    "\n",
    "Xtrain.shape, Xtest.shape, ytrain.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 31716,
     "status": "ok",
     "timestamp": 1602478435501,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "VBvWzipfcZDK",
    "outputId": "af402f16-e7ee-4272-c243-ae05646c8317"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5124, 32, 32, 3, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = Xtrain.reshape(-1, windowSize, windowSize, K, 1)\n",
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 31703,
     "status": "ok",
     "timestamp": 1602478435502,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "lxr7HMjocZvd",
    "outputId": "cb12450a-7ffc-44a2-d57b-2e42e0402ec4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5124, 16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain = np_utils.to_categorical(ytrain)\n",
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 31691,
     "status": "ok",
     "timestamp": 1602478435502,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "pAmd40PJcdog"
   },
   "outputs": [],
   "source": [
    "S1 = windowSize\n",
    "L1 = K\n",
    "output_units = 9 if (dataset == 'PU' or dataset == 'PC') else 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CoordAtt(x, reduction=32, bn_trainable=False):\n",
    "    def coord_act(x):\n",
    "        tmpx = (ReLU(max_value=6)(x + 3)) / 6\n",
    "        x = x * tmpx\n",
    "        return x\n",
    "\n",
    "    x_shape = x.shape.as_list()\n",
    "    [b, h, w, c] = x_shape\n",
    "    x_h = AveragePooling2D(pool_size=(1, w), strides=(1, 1), data_format='channels_last')(x)\n",
    "    x_w = AveragePooling2D(pool_size=(h, 1), strides=(1, 1), data_format='channels_last')(x)\n",
    "    x_w = backend.permute_dimensions(x_w, [0, 2, 1, 3])\n",
    "    y = concatenate(inputs=[x_h, x_w], axis=1)\n",
    "    mip = max(8, c // reduction)\n",
    "    y = Conv2D(filters=mip, kernel_size=(1, 1), strides=(1, 1), padding='valid')(y)\n",
    "    y = BatchNormalization(trainable=bn_trainable)(y)\n",
    "    y = coord_act(y)\n",
    "    x_h, x_w = Lambda(tf.split, arguments={'axis': 1, 'num_or_size_splits': [h, w]})(y)\n",
    "    x_w = backend.permute_dimensions(x_w, [0, 2, 1, 3])\n",
    "    a_h = Conv2D(filters=c, kernel_size=(1, 1), strides=(1, 1), padding='valid', activation=\"sigmoid\")(x_h)\n",
    "    a_w = Conv2D(filters=c, kernel_size=(1, 1), strides=(1, 1), padding='valid', activation=\"sigmoid\")(x_w)\n",
    "    out = x * a_h * a_w\n",
    "    return out\n",
    "\n",
    "\n",
    "def ConvBNReLU(inputs, filters, kernel_size, strides):\n",
    "    x = tf.keras.layers.Conv2D(filters=filters,\n",
    "                                  kernel_size=kernel_size,\n",
    "                                  strides=strides,\n",
    "                                  padding='same',\n",
    "                                  kernel_regularizer=tf.keras.regularizers.l2(4e-5),\n",
    "                                  use_bias=False,)(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization(momentum=0.9)(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def DWConvBN(inputs, strides = 1):\n",
    "    x = layers.DepthwiseConv2D(kernel_size=(3, 3),\n",
    "                                              strides=strides,\n",
    "                                              padding='same',\n",
    "                                              use_bias=False,\n",
    "                                              kernel_regularizer=tf.keras.regularizers.l2(4e-5),\n",
    "                              )(inputs)\n",
    "    x = layers.BatchNormalization(momentum=0.9)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def aspp_1(tensor, filter):\n",
    "    '''atrous spatial pyramid pooling'''\n",
    "    dims = backend.int_shape(tensor)\n",
    "    y_pool = tf.keras.layers.AveragePooling2D(pool_size=(\n",
    "        dims[1], dims[2]))(tensor)\n",
    "    y_pool = tf.keras.layers.DepthwiseConv2D(kernel_size=(1, 1),\n",
    "                                             padding='same',\n",
    "                                             use_bias=False,\n",
    "                                             kernel_regularizer=tf.keras.regularizers.l2(4e-5),)(y_pool)\n",
    "\n",
    "    y_pool = tf.keras.layers.UpSampling2D(size=[dims[1], dims[2]])(y_pool)\n",
    "\n",
    "    ## 1x1 conv\n",
    "    y_1 = tf.keras.layers.DepthwiseConv2D( kernel_size=(3, 3),\n",
    "                                           dilation_rate=(1, 1),\n",
    "                                           padding='same',\n",
    "                                           use_bias=False,\n",
    "                                           kernel_regularizer=tf.keras.regularizers.l2(4e-5))(tensor)\n",
    "\n",
    "\n",
    "    ## 3x3 dilated conv\n",
    "    y_6 = tf.keras.layers.DepthwiseConv2D(kernel_size=(3, 3),\n",
    "                                          dilation_rate=(6, 6),\n",
    "                                          padding='same',\n",
    "                                          use_bias=False,\n",
    "                                          kernel_regularizer=tf.keras.regularizers.l2(4e-5))(tensor)\n",
    "\n",
    "\n",
    "    ## 3x3 dilated conv\n",
    "    y_12 = tf.keras.layers.DepthwiseConv2D( kernel_size=(3, 3),\n",
    "                                            dilation_rate=(12, 12),\n",
    "                                            padding='same',\n",
    "                                            use_bias=False,\n",
    "                                            kernel_regularizer=tf.keras.regularizers.l2(4e-5))(tensor)\n",
    "\n",
    "\n",
    "    ## 3x3 dilated conv\n",
    "    y_18 = tf.keras.layers.DepthwiseConv2D( kernel_size=(3, 3),\n",
    "                                            dilation_rate=(18, 18),\n",
    "                                            padding='same',\n",
    "                                            use_bias=False,\n",
    "                                            kernel_regularizer=tf.keras.regularizers.l2(4e-5))(tensor)\n",
    "\n",
    "\n",
    "    ## concat\n",
    "    y = tf.keras.layers.concatenate([y_pool, y_1, y_6, y_12, y_18],)\n",
    "    y = tf.keras.layers.Conv2D(filters=filter, kernel_size=1,\n",
    "                                dilation_rate=1, padding='same',\n",
    "                                kernel_initializer='he_normal',\n",
    "\n",
    "                                use_bias=False)(y)\n",
    "    y = CoordAtt(y)\n",
    "\n",
    "    return y\n",
    "\n",
    "def aspp_2(tensor, filter):\n",
    "    '''atrous spatial pyramid pooling'''\n",
    "    dims = backend.int_shape(tensor)\n",
    "    y_pool = tf.keras.layers.AveragePooling2D(pool_size=(\n",
    "        dims[1], dims[2]))(tensor)\n",
    "    y_pool = tf.keras.layers.DepthwiseConv2D(kernel_size=(2, 2),\n",
    "                                             strides=(2, 2),\n",
    "                                             padding='same',\n",
    "                                             use_bias=False,\n",
    "                                             kernel_regularizer=tf.keras.regularizers.l2(4e-5), )(y_pool)\n",
    "    y_pool = tf.keras.layers.UpSampling2D(size=[dims[1]/2, dims[2]/2])(y_pool)\n",
    "\n",
    "    ## 1x1 conv\n",
    "    y_1 = tf.keras.layers.DepthwiseConv2D(kernel_size=(2, 2),\n",
    "                                          strides=(2, 2),\n",
    "                                          dilation_rate=(1, 1),\n",
    "                                          padding='same',\n",
    "                                          use_bias=False,\n",
    "                                          kernel_regularizer=tf.keras.regularizers.l2(4e-5))(tensor)\n",
    "\n",
    "    ## 3x3 dilated conv\n",
    "    y_6 = tf.keras.layers.DepthwiseConv2D(kernel_size=(2, 2),\n",
    "                                          strides=(2, 2),\n",
    "                                          padding='same',\n",
    "                                          use_bias=False)(tensor)\n",
    "    y_6 = tf.keras.layers.DepthwiseConv2D(kernel_size=(3, 3),\n",
    "                                         strides=(1, 1),\n",
    "                                         dilation_rate=(6, 6),\n",
    "                                         padding='same',\n",
    "                                         use_bias=False,\n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(4e-5))(y_6)\n",
    "\n",
    "    ## 3x3 dilated conv\n",
    "    y_12 = tf.keras.layers.DepthwiseConv2D(kernel_size=(2, 2),\n",
    "                                           strides=(2, 2),\n",
    "                                           padding='same',\n",
    "                                           use_bias=False)(tensor)\n",
    "    y_12 = tf.keras.layers.DepthwiseConv2D(kernel_size=(3, 3),\n",
    "                                           dilation_rate=(12, 12),\n",
    "                                           strides=(1, 1),\n",
    "                                           padding='same',\n",
    "                                           use_bias=False,\n",
    "                                           kernel_regularizer=tf.keras.regularizers.l2(4e-5))(y_12)\n",
    "\n",
    "    ## 3x3 dilated conv\n",
    "    y_18 = tf.keras.layers.DepthwiseConv2D(kernel_size=(2, 2),\n",
    "                                           strides=(2, 2),\n",
    "                                           padding='same',\n",
    "                                           use_bias=False)(tensor)\n",
    "    y_18 = tf.keras.layers.DepthwiseConv2D(kernel_size=(3, 3),\n",
    "                                           strides=(1, 1),\n",
    "                                           dilation_rate=(18, 18),\n",
    "                                           padding='same',\n",
    "                                           use_bias=False,\n",
    "                                           kernel_regularizer=tf.keras.regularizers.l2(4e-5))(y_18)\n",
    "\n",
    "    ## concat\n",
    "    y = tf.keras.layers.concatenate([y_pool, y_1, y_6, y_12, y_18], )\n",
    "    y = tf.keras.layers.Conv2D(filters=filter, kernel_size=1,\n",
    "                               dilation_rate=1, padding='same',\n",
    "                               kernel_initializer='he_normal',\n",
    "\n",
    "                               use_bias=False)(y)\n",
    "    y = CoordAtt(y)\n",
    "\n",
    "    return y\n",
    "\n",
    "def ChannelShuffle(inputs,shape):\n",
    "    # def __init__(self, shape, groups: int = 2, **kwargs):\n",
    "    # 先得到输入特征图的shape，b:batch size，h,w:一张图的size，c:通道数\n",
    "    b, h, w, c = shape\n",
    "    groups = 2\n",
    "    # 确定shape = [b, h, w, num, c//num]。通道维度原来是一个长为c的一维tensor，变成2行n列的矩阵\n",
    "    # 在通道维度上将特征图reshape为2行n列的矩阵。\n",
    "    x_reshaped = tf.reshape(inputs, [-1, h, w, groups, c // groups])\n",
    "\n",
    "    # 确定转置的矩形的shape = [b, h, w, c//num, num]\n",
    "    # 矩阵转置，最后两个维度从2行n列变成n行2列\n",
    "    x_transposed = tf.transpose(x_reshaped, [0, 1, 2, 4, 3])\n",
    "\n",
    "    # 重新排列，shotcut和x的通道像素交叉排列，通道维度重新变成一维tensor\n",
    "    x = tf.reshape(x_transposed, [-1, h, w, c])\n",
    "\n",
    "    return x\n",
    "\n",
    "def ChannelSplit(inputs):\n",
    "    num_splits: int = 2\n",
    "    b1, b2 = tf.split(inputs,\n",
    "                      num_or_size_splits=num_splits,\n",
    "                      axis=-1)\n",
    "    return b1, b2\n",
    "\n",
    "\n",
    "\n",
    "def shuffle_block_s1(inputs, output_c: int, stride: int):\n",
    "    if stride != 1:\n",
    "        raise ValueError(\"illegal stride value.\")\n",
    "\n",
    "    assert output_c % 2 == 0\n",
    "    branch_c = output_c // 2\n",
    "\n",
    "    x1, x2 = ChannelSplit(inputs)\n",
    "\n",
    "    # main branch\n",
    "    x2 = ConvBNReLU(x2, filters=branch_c, kernel_size=1, strides=1)\n",
    "#     x2 = DWConvBN(x2, strides=stride)\n",
    "    x2 = aspp_1(x2, branch_c)\n",
    "    x2 = ConvBNReLU(x2, filters=branch_c, kernel_size=1, strides=1)\n",
    "\n",
    "    out_put = layers.concatenate([x1, x2],axis=-1)\n",
    "\n",
    "    x = ChannelShuffle(out_put,out_put.shape)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def shuffle_block_s2(inputs, output_c: int, stride: int):\n",
    "    if stride != 2:\n",
    "        raise ValueError(\"illegal stride value.\")\n",
    "\n",
    "    assert output_c % 2 == 0\n",
    "    branch_c = output_c // 2\n",
    "\n",
    "    # shortcut branch\n",
    "    x1 = DWConvBN(inputs, strides=stride)\n",
    "    x1 = ConvBNReLU(x1,filters=branch_c,kernel_size=1, strides=1)\n",
    "\n",
    "    # main branch\n",
    "    x2 = ConvBNReLU(inputs,filters=branch_c,kernel_size=1, strides=1)\n",
    "#     x2 = DWConvBN(x2, strides=stride)\n",
    "    x2 = aspp_2(x2, branch_c)\n",
    "    x2 = ConvBNReLU(x2,filters=branch_c,kernel_size=1, strides=1)\n",
    "\n",
    "    out_put = layers.concatenate([x1, x2],axis=-1)\n",
    "    x = ChannelShuffle(out_put,out_put.shape)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def _make_layer(repeat_num, inputs, output_c, stride_1, stride_2):\n",
    "    block = tf.keras.Sequential()\n",
    "    block.add(shuffle_block_s2(inputs, output_c, stride_2))\n",
    "    for i in range(1, repeat_num):\n",
    "        block.add(shuffle_block_s1(inputs, output_c, stride_1))\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShuffleNet(img_input, ):\n",
    "    input_ = Input(img_input, name='the_input')\n",
    "    # Block 1\n",
    "    repeat =[4,8,4]\n",
    "    # 32,32,3 -> 32,32,64\n",
    "    x = Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      kernel_initializer = RandomNormal(stddev=0.02),\n",
    "                      name='block1_conv1')(input_)\n",
    "\n",
    "#     feat1 = x\n",
    "    # 32,32,32 -> 16,16,64\n",
    "    x = ConvBNReLU(x,\n",
    "                   filters=128,\n",
    "                   kernel_size=3,\n",
    "                   strides=2)\n",
    "#     feat2 = x\n",
    "\n",
    "\n",
    "    x = shuffle_block_s2(x, output_c=256, stride=2)\n",
    "    for i in (1, repeat[0]):\n",
    "        x = shuffle_block_s1(x, output_c=256, stride=1)\n",
    "#     feat3 = x\n",
    "\n",
    "    x = shuffle_block_s2(x, output_c=512, stride=2)\n",
    "    for i in (1, repeat[1]):\n",
    "        x = shuffle_block_s1(x, output_c=512, stride=1)\n",
    "#     feat4 = x\n",
    "\n",
    "    x = shuffle_block_s2(x, output_c=1024, stride=2)\n",
    "    for i in (1, repeat[2]):\n",
    "        x = shuffle_block_s1(x, output_c=1024, stride=1)\n",
    "#     feat5 = x\n",
    "#     x = ConvBNReLU(x, filters=2048 , kernel_size=1, strides=1)\n",
    "    x = layers.GlobalAveragePooling2D(name=\"globalpool\")(x)\n",
    "    x = layers.Dense(units=output_units, name=\"fc\")(x)\n",
    "    x = layers.Softmax()(x)\n",
    "    model = Model(inputs=input_, outputs=x)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 32872,
     "status": "ok",
     "timestamp": 1602478436734,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "iVgd4QmzgKKq",
    "outputId": "32d4779c-5699-49b0-eaef-613ac3ef7968",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 19:23:24.838311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-17 19:23:24.886840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-17 19:23:24.887138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-17 19:23:24.894024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-17 19:23:24.894555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-17 19:23:24.895027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-17 19:23:25.829463: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-17 19:23:25.829760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-17 19:23:25.829970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-17 19:23:25.830156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11428 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:02:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " the_input (InputLayer)         [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 32, 32, 64)   1792        ['the_input[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 16, 16, 128)  73728       ['block1_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 16, 16, 128)  512        ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 16, 16, 128)  0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 16, 16, 128)  16384       ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 16, 16, 128)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 1, 1, 128)   0           ['re_lu_2[0][0]']                \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_1 (DepthwiseC  (None, 1, 1, 128)   512         ['average_pooling2d[0][0]']      \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_3 (DepthwiseC  (None, 8, 8, 128)   512         ['re_lu_2[0][0]']                \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_5 (DepthwiseC  (None, 8, 8, 128)   512         ['re_lu_2[0][0]']                \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_7 (DepthwiseC  (None, 8, 8, 128)   512         ['re_lu_2[0][0]']                \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 8, 8, 128)    0           ['depthwise_conv2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " depthwise_conv2d_2 (DepthwiseC  (None, 8, 8, 128)   512         ['re_lu_2[0][0]']                \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_4 (DepthwiseC  (None, 8, 8, 128)   1152        ['depthwise_conv2d_3[0][0]']     \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_6 (DepthwiseC  (None, 8, 8, 128)   1152        ['depthwise_conv2d_5[0][0]']     \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_8 (DepthwiseC  (None, 8, 8, 128)   1152        ['depthwise_conv2d_7[0][0]']     \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 8, 8, 640)    0           ['up_sampling2d[0][0]',          \n",
      "                                                                  'depthwise_conv2d_2[0][0]',     \n",
      "                                                                  'depthwise_conv2d_4[0][0]',     \n",
      "                                                                  'depthwise_conv2d_6[0][0]',     \n",
      "                                                                  'depthwise_conv2d_8[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 8, 8, 128)    81920       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 1, 8, 128)   0           ['conv2d_3[0][0]']               \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 8, 1, 128)   0           ['conv2d_3[0][0]']               \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose (TFOpLa  (None, 8, 1, 128)   0           ['average_pooling2d_2[0][0]']    \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 16, 1, 128)   0           ['average_pooling2d_1[0][0]',    \n",
      "                                                                  'tf.compat.v1.transpose[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 16, 1, 8)     1032        ['tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 16, 1, 8)    32          ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 16, 1, 8)    0           ['batch_normalization_4[0][0]']  \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 16, 1, 8)     0           ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " tf.math.truediv (TFOpLambda)   (None, 16, 1, 8)     0           ['re_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 16, 1, 8)     0           ['batch_normalization_4[0][0]',  \n",
      "                                                                  'tf.math.truediv[0][0]']        \n",
      "                                                                                                  \n",
      " lambda (Lambda)                [(None, 8, 1, 8),    0           ['tf.math.multiply[0][0]']       \n",
      "                                 (None, 8, 1, 8)]                                                 \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 8, 1, 128)    1152        ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_1 (TFOp  (None, 1, 8, 8)     0           ['lambda[0][1]']                 \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d (DepthwiseCon  (None, 8, 8, 128)   1152        ['re_lu[0][0]']                  \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None, 8, 8, 128)   0           ['conv2d_3[0][0]',               \n",
      " )                                                                'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 1, 8, 128)    1152        ['tf.compat.v1.transpose_1[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 8, 8, 128)   512         ['depthwise_conv2d[0][0]']       \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLambda  (None, 8, 8, 128)   0           ['tf.math.multiply_1[0][0]',     \n",
      " )                                                                'conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 8, 8, 128)    16384       ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 8, 8, 128)    16384       ['tf.math.multiply_2[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 8, 8, 128)   512         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 8, 8, 128)   512         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 8, 8, 128)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 8, 8, 128)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 8, 8, 256)    0           ['re_lu_1[0][0]',                \n",
      "                                                                  're_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)        (None, 8, 8, 2, 128  0           ['concatenate_1[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_2 (TFOp  (None, 8, 8, 128, 2  0          ['tf.reshape[0][0]']             \n",
      " Lambda)                        )                                                                 \n",
      "                                                                                                  \n",
      " tf.reshape_1 (TFOpLambda)      (None, 8, 8, 256)    0           ['tf.compat.v1.transpose_2[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.split (TFOpLambda)          [(None, 8, 8, 128),  0           ['tf.reshape_1[0][0]']           \n",
      "                                 (None, 8, 8, 128)]                                               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 8, 8, 128)    16384       ['tf.split[0][1]']               \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 8, 8, 128)   512         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 8, 8, 128)    0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 1, 1, 128)   0           ['re_lu_5[0][0]']                \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " depthwise_conv2d_9 (DepthwiseC  (None, 1, 1, 128)   128         ['average_pooling2d_3[0][0]']    \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 8, 8, 128)   0           ['depthwise_conv2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " depthwise_conv2d_10 (Depthwise  (None, 8, 8, 128)   1152        ['re_lu_5[0][0]']                \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_11 (Depthwise  (None, 8, 8, 128)   1152        ['re_lu_5[0][0]']                \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_12 (Depthwise  (None, 8, 8, 128)   1152        ['re_lu_5[0][0]']                \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_13 (Depthwise  (None, 8, 8, 128)   1152        ['re_lu_5[0][0]']                \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 8, 8, 640)    0           ['up_sampling2d_1[0][0]',        \n",
      "                                                                  'depthwise_conv2d_10[0][0]',    \n",
      "                                                                  'depthwise_conv2d_11[0][0]',    \n",
      "                                                                  'depthwise_conv2d_12[0][0]',    \n",
      "                                                                  'depthwise_conv2d_13[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 8, 8, 128)    81920       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 1, 8, 128)   0           ['conv2d_9[0][0]']               \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 8, 1, 128)   0           ['conv2d_9[0][0]']               \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_3 (TFOp  (None, 8, 1, 128)   0           ['average_pooling2d_5[0][0]']    \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)       (None, 16, 1, 128)   0           ['average_pooling2d_4[0][0]',    \n",
      "                                                                  'tf.compat.v1.transpose_3[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 16, 1, 8)     1032        ['tf.concat_1[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 1, 8)    32          ['conv2d_10[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 16, 1, 8)    0           ['batch_normalization_7[0][0]']  \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)                 (None, 16, 1, 8)     0           ['tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.truediv_1 (TFOpLambda)  (None, 16, 1, 8)    0           ['re_lu_6[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLambda  (None, 16, 1, 8)    0           ['batch_normalization_7[0][0]',  \n",
      " )                                                                'tf.math.truediv_1[0][0]']      \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              [(None, 8, 1, 8),    0           ['tf.math.multiply_3[0][0]']     \n",
      "                                 (None, 8, 1, 8)]                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 8, 1, 128)    1152        ['lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_4 (TFOp  (None, 1, 8, 8)     0           ['lambda_1[0][1]']               \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLambda  (None, 8, 8, 128)   0           ['conv2d_9[0][0]',               \n",
      " )                                                                'conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 1, 8, 128)    1152        ['tf.compat.v1.transpose_4[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLambda  (None, 8, 8, 128)   0           ['tf.math.multiply_4[0][0]',     \n",
      " )                                                                'conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 8, 8, 128)    16384       ['tf.math.multiply_5[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 8, 8, 128)   512         ['conv2d_13[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)                 (None, 8, 8, 128)    0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 8, 8, 256)    0           ['tf.split[0][0]',               \n",
      "                                                                  're_lu_7[0][0]']                \n",
      "                                                                                                  \n",
      " tf.reshape_2 (TFOpLambda)      (None, 8, 8, 2, 128  0           ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_5 (TFOp  (None, 8, 8, 128, 2  0          ['tf.reshape_2[0][0]']           \n",
      " Lambda)                        )                                                                 \n",
      "                                                                                                  \n",
      " tf.reshape_3 (TFOpLambda)      (None, 8, 8, 256)    0           ['tf.compat.v1.transpose_5[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.split_1 (TFOpLambda)        [(None, 8, 8, 128),  0           ['tf.reshape_3[0][0]']           \n",
      "                                 (None, 8, 8, 128)]                                               \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 8, 8, 128)    16384       ['tf.split_1[0][1]']             \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 8, 8, 128)   512         ['conv2d_14[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)                 (None, 8, 8, 128)    0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 1, 1, 128)   0           ['re_lu_8[0][0]']                \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " depthwise_conv2d_14 (Depthwise  (None, 1, 1, 128)   128         ['average_pooling2d_6[0][0]']    \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 8, 8, 128)   0           ['depthwise_conv2d_14[0][0]']    \n",
      "                                                                                                  \n",
      " depthwise_conv2d_15 (Depthwise  (None, 8, 8, 128)   1152        ['re_lu_8[0][0]']                \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_16 (Depthwise  (None, 8, 8, 128)   1152        ['re_lu_8[0][0]']                \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_17 (Depthwise  (None, 8, 8, 128)   1152        ['re_lu_8[0][0]']                \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_18 (Depthwise  (None, 8, 8, 128)   1152        ['re_lu_8[0][0]']                \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 8, 8, 640)    0           ['up_sampling2d_2[0][0]',        \n",
      "                                                                  'depthwise_conv2d_15[0][0]',    \n",
      "                                                                  'depthwise_conv2d_16[0][0]',    \n",
      "                                                                  'depthwise_conv2d_17[0][0]',    \n",
      "                                                                  'depthwise_conv2d_18[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 8, 8, 128)    81920       ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 1, 8, 128)   0           ['conv2d_15[0][0]']              \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 8, 1, 128)   0           ['conv2d_15[0][0]']              \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_6 (TFOp  (None, 8, 1, 128)   0           ['average_pooling2d_8[0][0]']    \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.concat_2 (TFOpLambda)       (None, 16, 1, 128)   0           ['average_pooling2d_7[0][0]',    \n",
      "                                                                  'tf.compat.v1.transpose_6[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 16, 1, 8)     1032        ['tf.concat_2[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 16, 1, 8)    32          ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 16, 1, 8)    0           ['batch_normalization_10[0][0]'] \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)                 (None, 16, 1, 8)     0           ['tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.truediv_2 (TFOpLambda)  (None, 16, 1, 8)    0           ['re_lu_9[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLambda  (None, 16, 1, 8)    0           ['batch_normalization_10[0][0]', \n",
      " )                                                                'tf.math.truediv_2[0][0]']      \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              [(None, 8, 1, 8),    0           ['tf.math.multiply_6[0][0]']     \n",
      "                                 (None, 8, 1, 8)]                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 8, 1, 128)    1152        ['lambda_2[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_7 (TFOp  (None, 1, 8, 8)     0           ['lambda_2[0][1]']               \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.math.multiply_7 (TFOpLambda  (None, 8, 8, 128)   0           ['conv2d_15[0][0]',              \n",
      " )                                                                'conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 1, 8, 128)    1152        ['tf.compat.v1.transpose_7[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_8 (TFOpLambda  (None, 8, 8, 128)   0           ['tf.math.multiply_7[0][0]',     \n",
      " )                                                                'conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 8, 8, 128)    16384       ['tf.math.multiply_8[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 8, 8, 128)   512         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)                (None, 8, 8, 128)    0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 8, 8, 256)    0           ['tf.split_1[0][0]',             \n",
      "                                                                  're_lu_10[0][0]']               \n",
      "                                                                                                  \n",
      " tf.reshape_4 (TFOpLambda)      (None, 8, 8, 2, 128  0           ['concatenate_5[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_8 (TFOp  (None, 8, 8, 128, 2  0          ['tf.reshape_4[0][0]']           \n",
      " Lambda)                        )                                                                 \n",
      "                                                                                                  \n",
      " tf.reshape_5 (TFOpLambda)      (None, 8, 8, 256)    0           ['tf.compat.v1.transpose_8[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 8, 8, 256)    65536       ['tf.reshape_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)                (None, 8, 8, 256)    0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_9 (AveragePo  (None, 1, 1, 256)   0           ['re_lu_12[0][0]']               \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " depthwise_conv2d_20 (Depthwise  (None, 1, 1, 256)   1024        ['average_pooling2d_9[0][0]']    \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_22 (Depthwise  (None, 4, 4, 256)   1024        ['re_lu_12[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_24 (Depthwise  (None, 4, 4, 256)   1024        ['re_lu_12[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_26 (Depthwise  (None, 4, 4, 256)   1024        ['re_lu_12[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 4, 4, 256)   0           ['depthwise_conv2d_20[0][0]']    \n",
      "                                                                                                  \n",
      " depthwise_conv2d_21 (Depthwise  (None, 4, 4, 256)   1024        ['re_lu_12[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_23 (Depthwise  (None, 4, 4, 256)   2304        ['depthwise_conv2d_22[0][0]']    \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_25 (Depthwise  (None, 4, 4, 256)   2304        ['depthwise_conv2d_24[0][0]']    \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_27 (Depthwise  (None, 4, 4, 256)   2304        ['depthwise_conv2d_26[0][0]']    \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 4, 4, 1280)   0           ['up_sampling2d_3[0][0]',        \n",
      "                                                                  'depthwise_conv2d_21[0][0]',    \n",
      "                                                                  'depthwise_conv2d_23[0][0]',    \n",
      "                                                                  'depthwise_conv2d_25[0][0]',    \n",
      "                                                                  'depthwise_conv2d_27[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 4, 4, 256)    327680      ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_11 (AverageP  (None, 1, 4, 256)   0           ['conv2d_22[0][0]']              \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " average_pooling2d_10 (AverageP  (None, 4, 1, 256)   0           ['conv2d_22[0][0]']              \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_9 (TFOp  (None, 4, 1, 256)   0           ['average_pooling2d_11[0][0]']   \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.concat_3 (TFOpLambda)       (None, 8, 1, 256)    0           ['average_pooling2d_10[0][0]',   \n",
      "                                                                  'tf.compat.v1.transpose_9[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 8, 1, 8)      2056        ['tf.concat_3[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 8, 1, 8)     32          ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 8, 1, 8)     0           ['batch_normalization_15[0][0]'] \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)                (None, 8, 1, 8)      0           ['tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.truediv_3 (TFOpLambda)  (None, 8, 1, 8)     0           ['re_lu_13[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.multiply_9 (TFOpLambda  (None, 8, 1, 8)     0           ['batch_normalization_15[0][0]', \n",
      " )                                                                'tf.math.truediv_3[0][0]']      \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)              [(None, 4, 1, 8),    0           ['tf.math.multiply_9[0][0]']     \n",
      "                                 (None, 4, 1, 8)]                                                 \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 4, 1, 256)    2304        ['lambda_3[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_10 (TFO  (None, 1, 4, 8)     0           ['lambda_3[0][1]']               \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " depthwise_conv2d_19 (Depthwise  (None, 4, 4, 256)   2304        ['tf.reshape_5[0][0]']           \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " tf.math.multiply_10 (TFOpLambd  (None, 4, 4, 256)   0           ['conv2d_22[0][0]',              \n",
      " a)                                                               'conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 1, 4, 256)    2304        ['tf.compat.v1.transpose_10[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 4, 4, 256)   1024        ['depthwise_conv2d_19[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.math.multiply_11 (TFOpLambd  (None, 4, 4, 256)   0           ['tf.math.multiply_10[0][0]',    \n",
      " a)                                                               'conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 4, 4, 256)    65536       ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 4, 4, 256)    65536       ['tf.math.multiply_11[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_14 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 4, 4, 512)    0           ['re_lu_11[0][0]',               \n",
      "                                                                  're_lu_14[0][0]']               \n",
      "                                                                                                  \n",
      " tf.reshape_6 (TFOpLambda)      (None, 4, 4, 2, 256  0           ['concatenate_7[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_11 (TFO  (None, 4, 4, 256, 2  0          ['tf.reshape_6[0][0]']           \n",
      " pLambda)                       )                                                                 \n",
      "                                                                                                  \n",
      " tf.reshape_7 (TFOpLambda)      (None, 4, 4, 512)    0           ['tf.compat.v1.transpose_11[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.split_2 (TFOpLambda)        [(None, 4, 4, 256),  0           ['tf.reshape_7[0][0]']           \n",
      "                                 (None, 4, 4, 256)]                                               \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 4, 4, 256)    65536       ['tf.split_2[0][1]']             \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_15 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_12 (AverageP  (None, 1, 1, 256)   0           ['re_lu_15[0][0]']               \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " depthwise_conv2d_28 (Depthwise  (None, 1, 1, 256)   256         ['average_pooling2d_12[0][0]']   \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 4, 4, 256)   0           ['depthwise_conv2d_28[0][0]']    \n",
      "                                                                                                  \n",
      " depthwise_conv2d_29 (Depthwise  (None, 4, 4, 256)   2304        ['re_lu_15[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_30 (Depthwise  (None, 4, 4, 256)   2304        ['re_lu_15[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_31 (Depthwise  (None, 4, 4, 256)   2304        ['re_lu_15[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_32 (Depthwise  (None, 4, 4, 256)   2304        ['re_lu_15[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 4, 4, 1280)   0           ['up_sampling2d_4[0][0]',        \n",
      "                                                                  'depthwise_conv2d_29[0][0]',    \n",
      "                                                                  'depthwise_conv2d_30[0][0]',    \n",
      "                                                                  'depthwise_conv2d_31[0][0]',    \n",
      "                                                                  'depthwise_conv2d_32[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 4, 4, 256)    327680      ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_14 (AverageP  (None, 1, 4, 256)   0           ['conv2d_28[0][0]']              \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " average_pooling2d_13 (AverageP  (None, 4, 1, 256)   0           ['conv2d_28[0][0]']              \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_12 (TFO  (None, 4, 1, 256)   0           ['average_pooling2d_14[0][0]']   \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.concat_4 (TFOpLambda)       (None, 8, 1, 256)    0           ['average_pooling2d_13[0][0]',   \n",
      "                                                                  'tf.compat.v1.transpose_12[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 8, 1, 8)      2056        ['tf.concat_4[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 8, 1, 8)     32          ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 8, 1, 8)     0           ['batch_normalization_18[0][0]'] \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " re_lu_16 (ReLU)                (None, 8, 1, 8)      0           ['tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.truediv_4 (TFOpLambda)  (None, 8, 1, 8)     0           ['re_lu_16[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.multiply_12 (TFOpLambd  (None, 8, 1, 8)     0           ['batch_normalization_18[0][0]', \n",
      " a)                                                               'tf.math.truediv_4[0][0]']      \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)              [(None, 4, 1, 8),    0           ['tf.math.multiply_12[0][0]']    \n",
      "                                 (None, 4, 1, 8)]                                                 \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 4, 1, 256)    2304        ['lambda_4[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_13 (TFO  (None, 1, 4, 8)     0           ['lambda_4[0][1]']               \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.math.multiply_13 (TFOpLambd  (None, 4, 4, 256)   0           ['conv2d_28[0][0]',              \n",
      " a)                                                               'conv2d_30[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 1, 4, 256)    2304        ['tf.compat.v1.transpose_13[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_14 (TFOpLambd  (None, 4, 4, 256)   0           ['tf.math.multiply_13[0][0]',    \n",
      " a)                                                               'conv2d_31[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 4, 4, 256)    65536       ['tf.math.multiply_14[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_17 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 4, 4, 512)    0           ['tf.split_2[0][0]',             \n",
      "                                                                  're_lu_17[0][0]']               \n",
      "                                                                                                  \n",
      " tf.reshape_8 (TFOpLambda)      (None, 4, 4, 2, 256  0           ['concatenate_9[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_14 (TFO  (None, 4, 4, 256, 2  0          ['tf.reshape_8[0][0]']           \n",
      " pLambda)                       )                                                                 \n",
      "                                                                                                  \n",
      " tf.reshape_9 (TFOpLambda)      (None, 4, 4, 512)    0           ['tf.compat.v1.transpose_14[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.split_3 (TFOpLambda)        [(None, 4, 4, 256),  0           ['tf.reshape_9[0][0]']           \n",
      "                                 (None, 4, 4, 256)]                                               \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 4, 4, 256)    65536       ['tf.split_3[0][1]']             \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_18 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_15 (AverageP  (None, 1, 1, 256)   0           ['re_lu_18[0][0]']               \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " depthwise_conv2d_33 (Depthwise  (None, 1, 1, 256)   256         ['average_pooling2d_15[0][0]']   \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSampling2D)  (None, 4, 4, 256)   0           ['depthwise_conv2d_33[0][0]']    \n",
      "                                                                                                  \n",
      " depthwise_conv2d_34 (Depthwise  (None, 4, 4, 256)   2304        ['re_lu_18[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_35 (Depthwise  (None, 4, 4, 256)   2304        ['re_lu_18[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_36 (Depthwise  (None, 4, 4, 256)   2304        ['re_lu_18[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_37 (Depthwise  (None, 4, 4, 256)   2304        ['re_lu_18[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 4, 4, 1280)   0           ['up_sampling2d_5[0][0]',        \n",
      "                                                                  'depthwise_conv2d_34[0][0]',    \n",
      "                                                                  'depthwise_conv2d_35[0][0]',    \n",
      "                                                                  'depthwise_conv2d_36[0][0]',    \n",
      "                                                                  'depthwise_conv2d_37[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 4, 4, 256)    327680      ['concatenate_10[0][0]']         \n",
      "                                                                                                  \n",
      " average_pooling2d_17 (AverageP  (None, 1, 4, 256)   0           ['conv2d_34[0][0]']              \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " average_pooling2d_16 (AverageP  (None, 4, 1, 256)   0           ['conv2d_34[0][0]']              \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_15 (TFO  (None, 4, 1, 256)   0           ['average_pooling2d_17[0][0]']   \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.concat_5 (TFOpLambda)       (None, 8, 1, 256)    0           ['average_pooling2d_16[0][0]',   \n",
      "                                                                  'tf.compat.v1.transpose_15[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 8, 1, 8)      2056        ['tf.concat_5[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 8, 1, 8)     32          ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 8, 1, 8)     0           ['batch_normalization_21[0][0]'] \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " re_lu_19 (ReLU)                (None, 8, 1, 8)      0           ['tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.truediv_5 (TFOpLambda)  (None, 8, 1, 8)     0           ['re_lu_19[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.multiply_15 (TFOpLambd  (None, 8, 1, 8)     0           ['batch_normalization_21[0][0]', \n",
      " a)                                                               'tf.math.truediv_5[0][0]']      \n",
      "                                                                                                  \n",
      " lambda_5 (Lambda)              [(None, 4, 1, 8),    0           ['tf.math.multiply_15[0][0]']    \n",
      "                                 (None, 4, 1, 8)]                                                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 4, 1, 256)    2304        ['lambda_5[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_16 (TFO  (None, 1, 4, 8)     0           ['lambda_5[0][1]']               \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.math.multiply_16 (TFOpLambd  (None, 4, 4, 256)   0           ['conv2d_34[0][0]',              \n",
      " a)                                                               'conv2d_36[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 1, 4, 256)    2304        ['tf.compat.v1.transpose_16[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_17 (TFOpLambd  (None, 4, 4, 256)   0           ['tf.math.multiply_16[0][0]',    \n",
      " a)                                                               'conv2d_37[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 4, 4, 256)    65536       ['tf.math.multiply_17[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_20 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 4, 4, 512)    0           ['tf.split_3[0][0]',             \n",
      "                                                                  're_lu_20[0][0]']               \n",
      "                                                                                                  \n",
      " tf.reshape_10 (TFOpLambda)     (None, 4, 4, 2, 256  0           ['concatenate_11[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_17 (TFO  (None, 4, 4, 256, 2  0          ['tf.reshape_10[0][0]']          \n",
      " pLambda)                       )                                                                 \n",
      "                                                                                                  \n",
      " tf.reshape_11 (TFOpLambda)     (None, 4, 4, 512)    0           ['tf.compat.v1.transpose_17[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 4, 4, 512)    262144      ['tf.reshape_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_22 (ReLU)                (None, 4, 4, 512)    0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_18 (AverageP  (None, 1, 1, 512)   0           ['re_lu_22[0][0]']               \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " depthwise_conv2d_39 (Depthwise  (None, 1, 1, 512)   2048        ['average_pooling2d_18[0][0]']   \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_41 (Depthwise  (None, 2, 2, 512)   2048        ['re_lu_22[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_43 (Depthwise  (None, 2, 2, 512)   2048        ['re_lu_22[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_45 (Depthwise  (None, 2, 2, 512)   2048        ['re_lu_22[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " up_sampling2d_6 (UpSampling2D)  (None, 2, 2, 512)   0           ['depthwise_conv2d_39[0][0]']    \n",
      "                                                                                                  \n",
      " depthwise_conv2d_40 (Depthwise  (None, 2, 2, 512)   2048        ['re_lu_22[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_42 (Depthwise  (None, 2, 2, 512)   4608        ['depthwise_conv2d_41[0][0]']    \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_44 (Depthwise  (None, 2, 2, 512)   4608        ['depthwise_conv2d_43[0][0]']    \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_46 (Depthwise  (None, 2, 2, 512)   4608        ['depthwise_conv2d_45[0][0]']    \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenate)   (None, 2, 2, 2560)   0           ['up_sampling2d_6[0][0]',        \n",
      "                                                                  'depthwise_conv2d_40[0][0]',    \n",
      "                                                                  'depthwise_conv2d_42[0][0]',    \n",
      "                                                                  'depthwise_conv2d_44[0][0]',    \n",
      "                                                                  'depthwise_conv2d_46[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 2, 2, 512)    1310720     ['concatenate_12[0][0]']         \n",
      "                                                                                                  \n",
      " average_pooling2d_20 (AverageP  (None, 1, 2, 512)   0           ['conv2d_41[0][0]']              \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " average_pooling2d_19 (AverageP  (None, 2, 1, 512)   0           ['conv2d_41[0][0]']              \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_18 (TFO  (None, 2, 1, 512)   0           ['average_pooling2d_20[0][0]']   \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.concat_6 (TFOpLambda)       (None, 4, 1, 512)    0           ['average_pooling2d_19[0][0]',   \n",
      "                                                                  'tf.compat.v1.transpose_18[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 4, 1, 16)     8208        ['tf.concat_6[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 4, 1, 16)    64          ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 4, 1, 16)    0           ['batch_normalization_26[0][0]'] \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " re_lu_23 (ReLU)                (None, 4, 1, 16)     0           ['tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.truediv_6 (TFOpLambda)  (None, 4, 1, 16)    0           ['re_lu_23[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.multiply_18 (TFOpLambd  (None, 4, 1, 16)    0           ['batch_normalization_26[0][0]', \n",
      " a)                                                               'tf.math.truediv_6[0][0]']      \n",
      "                                                                                                  \n",
      " lambda_6 (Lambda)              [(None, 2, 1, 16),   0           ['tf.math.multiply_18[0][0]']    \n",
      "                                 (None, 2, 1, 16)]                                                \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 2, 1, 512)    8704        ['lambda_6[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_19 (TFO  (None, 1, 2, 16)    0           ['lambda_6[0][1]']               \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " depthwise_conv2d_38 (Depthwise  (None, 2, 2, 512)   4608        ['tf.reshape_11[0][0]']          \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " tf.math.multiply_19 (TFOpLambd  (None, 2, 2, 512)   0           ['conv2d_41[0][0]',              \n",
      " a)                                                               'conv2d_43[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 1, 2, 512)    8704        ['tf.compat.v1.transpose_19[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 2, 2, 512)   2048        ['depthwise_conv2d_38[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.math.multiply_20 (TFOpLambd  (None, 2, 2, 512)   0           ['tf.math.multiply_19[0][0]',    \n",
      " a)                                                               'conv2d_44[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 2, 2, 512)    262144      ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 2, 2, 512)    262144      ['tf.math.multiply_20[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_21 (ReLU)                (None, 2, 2, 512)    0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_24 (ReLU)                (None, 2, 2, 512)    0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenate)   (None, 2, 2, 1024)   0           ['re_lu_21[0][0]',               \n",
      "                                                                  're_lu_24[0][0]']               \n",
      "                                                                                                  \n",
      " tf.reshape_12 (TFOpLambda)     (None, 2, 2, 2, 512  0           ['concatenate_13[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_20 (TFO  (None, 2, 2, 512, 2  0          ['tf.reshape_12[0][0]']          \n",
      " pLambda)                       )                                                                 \n",
      "                                                                                                  \n",
      " tf.reshape_13 (TFOpLambda)     (None, 2, 2, 1024)   0           ['tf.compat.v1.transpose_20[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.split_4 (TFOpLambda)        [(None, 2, 2, 512),  0           ['tf.reshape_13[0][0]']          \n",
      "                                 (None, 2, 2, 512)]                                               \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 2, 2, 512)    262144      ['tf.split_4[0][1]']             \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_25 (ReLU)                (None, 2, 2, 512)    0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_21 (AverageP  (None, 1, 1, 512)   0           ['re_lu_25[0][0]']               \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " depthwise_conv2d_47 (Depthwise  (None, 1, 1, 512)   512         ['average_pooling2d_21[0][0]']   \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " up_sampling2d_7 (UpSampling2D)  (None, 2, 2, 512)   0           ['depthwise_conv2d_47[0][0]']    \n",
      "                                                                                                  \n",
      " depthwise_conv2d_48 (Depthwise  (None, 2, 2, 512)   4608        ['re_lu_25[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_49 (Depthwise  (None, 2, 2, 512)   4608        ['re_lu_25[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_50 (Depthwise  (None, 2, 2, 512)   4608        ['re_lu_25[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_51 (Depthwise  (None, 2, 2, 512)   4608        ['re_lu_25[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenate)   (None, 2, 2, 2560)   0           ['up_sampling2d_7[0][0]',        \n",
      "                                                                  'depthwise_conv2d_48[0][0]',    \n",
      "                                                                  'depthwise_conv2d_49[0][0]',    \n",
      "                                                                  'depthwise_conv2d_50[0][0]',    \n",
      "                                                                  'depthwise_conv2d_51[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 2, 2, 512)    1310720     ['concatenate_14[0][0]']         \n",
      "                                                                                                  \n",
      " average_pooling2d_23 (AverageP  (None, 1, 2, 512)   0           ['conv2d_47[0][0]']              \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " average_pooling2d_22 (AverageP  (None, 2, 1, 512)   0           ['conv2d_47[0][0]']              \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_21 (TFO  (None, 2, 1, 512)   0           ['average_pooling2d_23[0][0]']   \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.concat_7 (TFOpLambda)       (None, 4, 1, 512)    0           ['average_pooling2d_22[0][0]',   \n",
      "                                                                  'tf.compat.v1.transpose_21[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 4, 1, 16)     8208        ['tf.concat_7[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 4, 1, 16)    64          ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 4, 1, 16)    0           ['batch_normalization_29[0][0]'] \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " re_lu_26 (ReLU)                (None, 4, 1, 16)     0           ['tf.__operators__.add_7[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.truediv_7 (TFOpLambda)  (None, 4, 1, 16)    0           ['re_lu_26[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.multiply_21 (TFOpLambd  (None, 4, 1, 16)    0           ['batch_normalization_29[0][0]', \n",
      " a)                                                               'tf.math.truediv_7[0][0]']      \n",
      "                                                                                                  \n",
      " lambda_7 (Lambda)              [(None, 2, 1, 16),   0           ['tf.math.multiply_21[0][0]']    \n",
      "                                 (None, 2, 1, 16)]                                                \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 2, 1, 512)    8704        ['lambda_7[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_22 (TFO  (None, 1, 2, 16)    0           ['lambda_7[0][1]']               \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.math.multiply_22 (TFOpLambd  (None, 2, 2, 512)   0           ['conv2d_47[0][0]',              \n",
      " a)                                                               'conv2d_49[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 1, 2, 512)    8704        ['tf.compat.v1.transpose_22[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_23 (TFOpLambd  (None, 2, 2, 512)   0           ['tf.math.multiply_22[0][0]',    \n",
      " a)                                                               'conv2d_50[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 2, 2, 512)    262144      ['tf.math.multiply_23[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_27 (ReLU)                (None, 2, 2, 512)    0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenate)   (None, 2, 2, 1024)   0           ['tf.split_4[0][0]',             \n",
      "                                                                  're_lu_27[0][0]']               \n",
      "                                                                                                  \n",
      " tf.reshape_14 (TFOpLambda)     (None, 2, 2, 2, 512  0           ['concatenate_15[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_23 (TFO  (None, 2, 2, 512, 2  0          ['tf.reshape_14[0][0]']          \n",
      " pLambda)                       )                                                                 \n",
      "                                                                                                  \n",
      " tf.reshape_15 (TFOpLambda)     (None, 2, 2, 1024)   0           ['tf.compat.v1.transpose_23[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.split_5 (TFOpLambda)        [(None, 2, 2, 512),  0           ['tf.reshape_15[0][0]']          \n",
      "                                 (None, 2, 2, 512)]                                               \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 2, 2, 512)    262144      ['tf.split_5[0][1]']             \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_28 (ReLU)                (None, 2, 2, 512)    0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_24 (AverageP  (None, 1, 1, 512)   0           ['re_lu_28[0][0]']               \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " depthwise_conv2d_52 (Depthwise  (None, 1, 1, 512)   512         ['average_pooling2d_24[0][0]']   \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " up_sampling2d_8 (UpSampling2D)  (None, 2, 2, 512)   0           ['depthwise_conv2d_52[0][0]']    \n",
      "                                                                                                  \n",
      " depthwise_conv2d_53 (Depthwise  (None, 2, 2, 512)   4608        ['re_lu_28[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_54 (Depthwise  (None, 2, 2, 512)   4608        ['re_lu_28[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_55 (Depthwise  (None, 2, 2, 512)   4608        ['re_lu_28[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_56 (Depthwise  (None, 2, 2, 512)   4608        ['re_lu_28[0][0]']               \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_16 (Concatenate)   (None, 2, 2, 2560)   0           ['up_sampling2d_8[0][0]',        \n",
      "                                                                  'depthwise_conv2d_53[0][0]',    \n",
      "                                                                  'depthwise_conv2d_54[0][0]',    \n",
      "                                                                  'depthwise_conv2d_55[0][0]',    \n",
      "                                                                  'depthwise_conv2d_56[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 2, 2, 512)    1310720     ['concatenate_16[0][0]']         \n",
      "                                                                                                  \n",
      " average_pooling2d_26 (AverageP  (None, 1, 2, 512)   0           ['conv2d_53[0][0]']              \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " average_pooling2d_25 (AverageP  (None, 2, 1, 512)   0           ['conv2d_53[0][0]']              \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_24 (TFO  (None, 2, 1, 512)   0           ['average_pooling2d_26[0][0]']   \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.concat_8 (TFOpLambda)       (None, 4, 1, 512)    0           ['average_pooling2d_25[0][0]',   \n",
      "                                                                  'tf.compat.v1.transpose_24[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 4, 1, 16)     8208        ['tf.concat_8[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 4, 1, 16)    64          ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TFOpLa  (None, 4, 1, 16)    0           ['batch_normalization_32[0][0]'] \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " re_lu_29 (ReLU)                (None, 4, 1, 16)     0           ['tf.__operators__.add_8[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.truediv_8 (TFOpLambda)  (None, 4, 1, 16)    0           ['re_lu_29[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.multiply_24 (TFOpLambd  (None, 4, 1, 16)    0           ['batch_normalization_32[0][0]', \n",
      " a)                                                               'tf.math.truediv_8[0][0]']      \n",
      "                                                                                                  \n",
      " lambda_8 (Lambda)              [(None, 2, 1, 16),   0           ['tf.math.multiply_24[0][0]']    \n",
      "                                 (None, 2, 1, 16)]                                                \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 2, 1, 512)    8704        ['lambda_8[0][0]']               \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_25 (TFO  (None, 1, 2, 16)    0           ['lambda_8[0][1]']               \n",
      " pLambda)                                                                                         \n",
      "                                                                                                  \n",
      " tf.math.multiply_25 (TFOpLambd  (None, 2, 2, 512)   0           ['conv2d_53[0][0]',              \n",
      " a)                                                               'conv2d_55[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 1, 2, 512)    8704        ['tf.compat.v1.transpose_25[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_26 (TFOpLambd  (None, 2, 2, 512)   0           ['tf.math.multiply_25[0][0]',    \n",
      " a)                                                               'conv2d_56[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 2, 2, 512)    262144      ['tf.math.multiply_26[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_30 (ReLU)                (None, 2, 2, 512)    0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenate)   (None, 2, 2, 1024)   0           ['tf.split_5[0][0]',             \n",
      "                                                                  're_lu_30[0][0]']               \n",
      "                                                                                                  \n",
      " tf.reshape_16 (TFOpLambda)     (None, 2, 2, 2, 512  0           ['concatenate_17[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_26 (TFO  (None, 2, 2, 512, 2  0          ['tf.reshape_16[0][0]']          \n",
      " pLambda)                       )                                                                 \n",
      "                                                                                                  \n",
      " tf.reshape_17 (TFOpLambda)     (None, 2, 2, 1024)   0           ['tf.compat.v1.transpose_26[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " globalpool (GlobalAveragePooli  (None, 1024)        0           ['tf.reshape_17[0][0]']          \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " fc (Dense)                     (None, 16)           16400       ['globalpool[0][0]']             \n",
      "                                                                                                  \n",
      " softmax (Softmax)              (None, 16)           0           ['fc[0][0]']                     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,914,224\n",
      "Trainable params: 7,899,248\n",
      "Non-trainable params: 14,976\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ShuffleNet(img_input=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 32861,
     "status": "ok",
     "timestamp": 1602478436735,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "OYsuViCjhSA3"
   },
   "outputs": [],
   "source": [
    "# adam = Adam(learning_rate=0.001, decay=1e-06)\n",
    "sgd = SGD(learning_rate=0.001, momentum=0.9, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 32854,
     "status": "ok",
     "timestamp": 1602478436736,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "sUQZa9UD-rsL"
   },
   "outputs": [],
   "source": [
    "filepath = \"best-model.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=False, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 417831,
     "status": "ok",
     "timestamp": 1602478821720,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "OVwsWGf1hfg3",
    "outputId": "66ced090-c536-4f79-9bee-71ded4683b4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 19:23:38.987212: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8500\n",
      "2023-05-17 19:23:39.781033: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-17 19:23:40.157888: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - ETA: 0s - loss: 2.2838 - accuracy: 0.3823\n",
      "Epoch 00001: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 21s 113ms/step - loss: 2.2838 - accuracy: 0.3823\n",
      "Epoch 2/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.2972 - accuracy: 0.7400\n",
      "Epoch 00002: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 1.2972 - accuracy: 0.7400\n",
      "Epoch 3/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.8668 - accuracy: 0.8628\n",
      "Epoch 00003: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 105ms/step - loss: 0.8668 - accuracy: 0.8628\n",
      "Epoch 4/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.6246 - accuracy: 0.9204\n",
      "Epoch 00004: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 106ms/step - loss: 0.6246 - accuracy: 0.9204\n",
      "Epoch 5/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.5061 - accuracy: 0.9571\n",
      "Epoch 00005: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.5061 - accuracy: 0.9571\n",
      "Epoch 6/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.4271 - accuracy: 0.9760\n",
      "Epoch 00006: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.4271 - accuracy: 0.9760\n",
      "Epoch 7/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.3661 - accuracy: 0.9858\n",
      "Epoch 00007: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.3661 - accuracy: 0.9858\n",
      "Epoch 8/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.3418 - accuracy: 0.9900\n",
      "Epoch 00008: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.3418 - accuracy: 0.9900\n",
      "Epoch 9/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.3289 - accuracy: 0.9930\n",
      "Epoch 00009: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.3289 - accuracy: 0.9930\n",
      "Epoch 10/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.3189 - accuracy: 0.9914\n",
      "Epoch 00010: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.3189 - accuracy: 0.9914\n",
      "Epoch 11/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.3054 - accuracy: 0.9938\n",
      "Epoch 00011: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.3054 - accuracy: 0.9938\n",
      "Epoch 12/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2921 - accuracy: 0.9961\n",
      "Epoch 00012: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2921 - accuracy: 0.9961\n",
      "Epoch 13/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2859 - accuracy: 0.9975\n",
      "Epoch 00013: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2859 - accuracy: 0.9975\n",
      "Epoch 14/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2846 - accuracy: 0.9965\n",
      "Epoch 00014: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2846 - accuracy: 0.9965\n",
      "Epoch 15/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2884 - accuracy: 0.9965\n",
      "Epoch 00015: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 106ms/step - loss: 0.2884 - accuracy: 0.9965\n",
      "Epoch 16/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2977 - accuracy: 0.9951\n",
      "Epoch 00016: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2977 - accuracy: 0.9951\n",
      "Epoch 17/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2828 - accuracy: 0.9975\n",
      "Epoch 00017: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2828 - accuracy: 0.9975\n",
      "Epoch 18/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2709 - accuracy: 0.9988\n",
      "Epoch 00018: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2709 - accuracy: 0.9988\n",
      "Epoch 19/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2722 - accuracy: 0.9992\n",
      "Epoch 00019: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 109ms/step - loss: 0.2722 - accuracy: 0.9992\n",
      "Epoch 20/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2736 - accuracy: 0.9992\n",
      "Epoch 00020: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2736 - accuracy: 0.9992\n",
      "Epoch 21/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2668 - accuracy: 0.9998\n",
      "Epoch 00021: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2668 - accuracy: 0.9998\n",
      "Epoch 22/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2664 - accuracy: 0.9998\n",
      "Epoch 00022: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2664 - accuracy: 0.9998\n",
      "Epoch 23/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2633 - accuracy: 0.9998\n",
      "Epoch 00023: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2633 - accuracy: 0.9998\n",
      "Epoch 24/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2639 - accuracy: 1.0000\n",
      "Epoch 00024: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 109ms/step - loss: 0.2639 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2657 - accuracy: 0.9990\n",
      "Epoch 00025: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2657 - accuracy: 0.9990\n",
      "Epoch 26/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2706 - accuracy: 0.9986\n",
      "Epoch 00026: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2706 - accuracy: 0.9986\n",
      "Epoch 27/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2648 - accuracy: 0.9996\n",
      "Epoch 00027: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2648 - accuracy: 0.9996\n",
      "Epoch 28/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2621 - accuracy: 0.9998\n",
      "Epoch 00028: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 106ms/step - loss: 0.2621 - accuracy: 0.9998\n",
      "Epoch 29/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2691 - accuracy: 0.9977\n",
      "Epoch 00029: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2691 - accuracy: 0.9977\n",
      "Epoch 30/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2712 - accuracy: 0.9986\n",
      "Epoch 00030: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2712 - accuracy: 0.9986\n",
      "Epoch 31/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2650 - accuracy: 0.9994\n",
      "Epoch 00031: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 106ms/step - loss: 0.2650 - accuracy: 0.9994\n",
      "Epoch 32/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2618 - accuracy: 0.9996\n",
      "Epoch 00032: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2618 - accuracy: 0.9996\n",
      "Epoch 33/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2594 - accuracy: 0.9998\n",
      "Epoch 00033: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2594 - accuracy: 0.9998\n",
      "Epoch 34/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2625 - accuracy: 0.9996\n",
      "Epoch 00034: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2625 - accuracy: 0.9996\n",
      "Epoch 35/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2722 - accuracy: 0.9971\n",
      "Epoch 00035: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 106ms/step - loss: 0.2722 - accuracy: 0.9971\n",
      "Epoch 36/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2599 - accuracy: 0.9998\n",
      "Epoch 00036: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2599 - accuracy: 0.9998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2665 - accuracy: 0.9986\n",
      "Epoch 00037: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 109ms/step - loss: 0.2665 - accuracy: 0.9986\n",
      "Epoch 38/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2759 - accuracy: 0.9963\n",
      "Epoch 00038: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2759 - accuracy: 0.9963\n",
      "Epoch 39/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2662 - accuracy: 0.9990\n",
      "Epoch 00039: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2662 - accuracy: 0.9990\n",
      "Epoch 40/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2722 - accuracy: 0.9980\n",
      "Epoch 00040: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2722 - accuracy: 0.9980\n",
      "Epoch 41/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2656 - accuracy: 0.9984\n",
      "Epoch 00041: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2656 - accuracy: 0.9984\n",
      "Epoch 42/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2597 - accuracy: 1.0000\n",
      "Epoch 00042: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 106ms/step - loss: 0.2597 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2610 - accuracy: 0.9992\n",
      "Epoch 00043: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 110ms/step - loss: 0.2610 - accuracy: 0.9992\n",
      "Epoch 44/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2572 - accuracy: 1.0000\n",
      "Epoch 00044: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2572 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2579 - accuracy: 1.0000\n",
      "Epoch 00045: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2579 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2585 - accuracy: 1.0000\n",
      "Epoch 00046: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2585 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2583 - accuracy: 0.9996\n",
      "Epoch 00047: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 106ms/step - loss: 0.2583 - accuracy: 0.9996\n",
      "Epoch 48/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2864 - accuracy: 0.9951\n",
      "Epoch 00048: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 106ms/step - loss: 0.2864 - accuracy: 0.9951\n",
      "Epoch 49/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2621 - accuracy: 0.9992\n",
      "Epoch 00049: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2621 - accuracy: 0.9992\n",
      "Epoch 50/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2699 - accuracy: 0.9977\n",
      "Epoch 00050: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2699 - accuracy: 0.9977\n",
      "Epoch 51/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2689 - accuracy: 0.9988\n",
      "Epoch 00051: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2689 - accuracy: 0.9988\n",
      "Epoch 52/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2607 - accuracy: 0.9998\n",
      "Epoch 00052: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2607 - accuracy: 0.9998\n",
      "Epoch 53/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2644 - accuracy: 0.9988\n",
      "Epoch 00053: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2644 - accuracy: 0.9988\n",
      "Epoch 54/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2583 - accuracy: 0.9998\n",
      "Epoch 00054: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2583 - accuracy: 0.9998\n",
      "Epoch 55/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2605 - accuracy: 0.9994\n",
      "Epoch 00055: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 106ms/step - loss: 0.2605 - accuracy: 0.9994\n",
      "Epoch 56/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2690 - accuracy: 0.9979\n",
      "Epoch 00056: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2690 - accuracy: 0.9979\n",
      "Epoch 57/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2588 - accuracy: 1.0000\n",
      "Epoch 00057: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2588 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2577 - accuracy: 0.9996\n",
      "Epoch 00058: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2577 - accuracy: 0.9996\n",
      "Epoch 59/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2631 - accuracy: 0.9988\n",
      "Epoch 00059: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2631 - accuracy: 0.9988\n",
      "Epoch 60/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2733 - accuracy: 0.9961\n",
      "Epoch 00060: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2733 - accuracy: 0.9961\n",
      "Epoch 61/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2585 - accuracy: 1.0000\n",
      "Epoch 00061: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2585 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2584 - accuracy: 0.9996\n",
      "Epoch 00062: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2584 - accuracy: 0.9996\n",
      "Epoch 63/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2702 - accuracy: 0.9963\n",
      "Epoch 00063: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2702 - accuracy: 0.9963\n",
      "Epoch 64/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2604 - accuracy: 0.9990\n",
      "Epoch 00064: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2604 - accuracy: 0.9990\n",
      "Epoch 65/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2621 - accuracy: 0.9986\n",
      "Epoch 00065: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2621 - accuracy: 0.9986\n",
      "Epoch 66/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2659 - accuracy: 0.9982\n",
      "Epoch 00066: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2659 - accuracy: 0.9982\n",
      "Epoch 67/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2598 - accuracy: 0.9992\n",
      "Epoch 00067: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 106ms/step - loss: 0.2598 - accuracy: 0.9992\n",
      "Epoch 68/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2566 - accuracy: 1.0000\n",
      "Epoch 00068: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2566 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2566 - accuracy: 0.9996\n",
      "Epoch 00069: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2566 - accuracy: 0.9996\n",
      "Epoch 70/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2780 - accuracy: 0.9951\n",
      "Epoch 00070: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2780 - accuracy: 0.9951\n",
      "Epoch 71/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2580 - accuracy: 1.0000\n",
      "Epoch 00071: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 106ms/step - loss: 0.2580 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2600 - accuracy: 0.9990\n",
      "Epoch 00072: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2600 - accuracy: 0.9990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2565 - accuracy: 0.9998\n",
      "Epoch 00073: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 106ms/step - loss: 0.2565 - accuracy: 0.9998\n",
      "Epoch 74/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2556 - accuracy: 0.9998\n",
      "Epoch 00074: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 106ms/step - loss: 0.2556 - accuracy: 0.9998\n",
      "Epoch 75/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2550 - accuracy: 1.0000\n",
      "Epoch 00075: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2550 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2549 - accuracy: 1.0000\n",
      "Epoch 00076: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2549 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2562 - accuracy: 0.9992\n",
      "Epoch 00077: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2562 - accuracy: 0.9992\n",
      "Epoch 78/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2707 - accuracy: 0.9963\n",
      "Epoch 00078: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2707 - accuracy: 0.9963\n",
      "Epoch 79/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2615 - accuracy: 0.9988\n",
      "Epoch 00079: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2615 - accuracy: 0.9988\n",
      "Epoch 80/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2620 - accuracy: 0.9984\n",
      "Epoch 00080: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2620 - accuracy: 0.9984\n",
      "Epoch 81/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2684 - accuracy: 0.9973\n",
      "Epoch 00081: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2684 - accuracy: 0.9973\n",
      "Epoch 82/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2618 - accuracy: 0.9988\n",
      "Epoch 00082: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2618 - accuracy: 0.9988\n",
      "Epoch 83/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2594 - accuracy: 0.9990\n",
      "Epoch 00083: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2594 - accuracy: 0.9990\n",
      "Epoch 84/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2563 - accuracy: 1.0000\n",
      "Epoch 00084: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 109ms/step - loss: 0.2563 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2552 - accuracy: 0.9998\n",
      "Epoch 00085: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 110ms/step - loss: 0.2552 - accuracy: 0.9998\n",
      "Epoch 86/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2558 - accuracy: 0.9994\n",
      "Epoch 00086: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2558 - accuracy: 0.9994\n",
      "Epoch 87/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2558 - accuracy: 0.9996\n",
      "Epoch 00087: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2558 - accuracy: 0.9996\n",
      "Epoch 88/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2616 - accuracy: 0.9984\n",
      "Epoch 00088: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2616 - accuracy: 0.9984\n",
      "Epoch 89/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2606 - accuracy: 0.9992\n",
      "Epoch 00089: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 105ms/step - loss: 0.2606 - accuracy: 0.9992\n",
      "Epoch 90/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2603 - accuracy: 0.9986\n",
      "Epoch 00090: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2603 - accuracy: 0.9986\n",
      "Epoch 91/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2562 - accuracy: 1.0000\n",
      "Epoch 00091: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2562 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2563 - accuracy: 0.9996\n",
      "Epoch 00092: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2563 - accuracy: 0.9996\n",
      "Epoch 93/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2595 - accuracy: 0.9984\n",
      "Epoch 00093: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2595 - accuracy: 0.9984\n",
      "Epoch 94/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2555 - accuracy: 0.9996\n",
      "Epoch 00094: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2555 - accuracy: 0.9996\n",
      "Epoch 95/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2548 - accuracy: 0.9998\n",
      "Epoch 00095: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2548 - accuracy: 0.9998\n",
      "Epoch 96/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2573 - accuracy: 0.9994\n",
      "Epoch 00096: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2573 - accuracy: 0.9994\n",
      "Epoch 97/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2539 - accuracy: 1.0000\n",
      "Epoch 00097: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2539 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2540 - accuracy: 1.0000\n",
      "Epoch 00098: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2540 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2545 - accuracy: 1.0000\n",
      "Epoch 00099: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.2545 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2532 - accuracy: 1.0000\n",
      "Epoch 00100: saving model to best-model.hdf5\n",
      "81/81 [==============================] - 9s 107ms/step - loss: 0.2532 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=Xtrain, y=ytrain, batch_size =64, epochs=100, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5-BLNivkkD2"
   },
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "executionInfo": {
     "elapsed": 417824,
     "status": "ok",
     "timestamp": 1602478821723,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "rzi0kGwckZIh",
    "outputId": "860ced41-4c23-4c7b-d0d9-88b35f1d005f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f59ac553ee0>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7)) \n",
    "plt.grid() \n",
    "plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "#plt.ylabel('Loss') \n",
    "#plt.xlabel('Epochs') \n",
    "#plt.legend(['Training','Validation'], loc='upper right') \n",
    "#plt.savefig(\"loss_curve.pdf\") \n",
    "#plt.show()\n",
    "#plt.figure(figsize=(5,5)) \n",
    "#plt.ylim(0,1.1) \n",
    "#plt.grid() \n",
    "#plt.plot(history.history['acc'])\n",
    "#plt.plot(history.history['val_acc'])\n",
    "#plt.ylabel('Accuracy') \n",
    "#plt.xlabel('Epochs') \n",
    "#plt.legend(['Training','Validation']) \n",
    "#plt.savefig(\"acc_curve.pdf\") \n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 418307,
     "status": "ok",
     "timestamp": 1602478822219,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "HKSPxOqckkD3"
   },
   "outputs": [],
   "source": [
    "# load best weights\n",
    "model.load_weights(\"best-model.hdf5\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 418301,
     "status": "ok",
     "timestamp": 1602478822220,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "tzGuqZILkkD5",
    "outputId": "58b28fd2-e2a8-47a5-94bd-3bb222491aa0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5125, 32, 32, 3, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest = Xtest.reshape(-1, windowSize, windowSize, K, 1)\n",
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 418293,
     "status": "ok",
     "timestamp": 1602478822221,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "FIhcrDHQkkD7",
    "outputId": "301bc50b-063d-4ad4-b84e-96658ec5bfee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5125, 16)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest = np_utils.to_categorical(ytest)\n",
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "executionInfo": {
     "elapsed": 427183,
     "status": "ok",
     "timestamp": 1602478831122,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "x9gnEB8wkkD-",
    "outputId": "38e44cce-3f72-40f7-b8e4-5914a2294f69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5125, 16)\n",
      "(5125,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        23\n",
      "           1       1.00      1.00      1.00       714\n",
      "           2       1.00      1.00      1.00       415\n",
      "           3       1.00      1.00      1.00       118\n",
      "           4       1.00      1.00      1.00       242\n",
      "           5       1.00      1.00      1.00       365\n",
      "           6       1.00      1.00      1.00        14\n",
      "           7       1.00      1.00      1.00       239\n",
      "           8       1.00      1.00      1.00        10\n",
      "           9       1.00      1.00      1.00       486\n",
      "          10       1.00      1.00      1.00      1228\n",
      "          11       1.00      1.00      1.00       297\n",
      "          12       1.00      1.00      1.00       102\n",
      "          13       1.00      1.00      1.00       633\n",
      "          14       1.00      1.00      1.00       193\n",
      "          15       0.98      1.00      0.99        46\n",
      "\n",
      "    accuracy                           1.00      5125\n",
      "   macro avg       1.00      1.00      1.00      5125\n",
      "weighted avg       1.00      1.00      1.00      5125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred_test = model.predict(Xtest)\n",
    "print(Y_pred_test.shape)\n",
    "y_pred_test = np.argmax(Y_pred_test, axis=1)\n",
    "print(y_pred_test.shape)\n",
    "classification = classification_report(np.argmax(ytest, axis=1), y_pred_test)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 427171,
     "status": "ok",
     "timestamp": 1602478831123,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "M8Z-62eCkkEA"
   },
   "outputs": [],
   "source": [
    "def AA_andEachClassAccuracy(confusion_matrix):\n",
    "    counter = confusion_matrix.shape[0]\n",
    "    list_diag = np.diag(confusion_matrix)\n",
    "    list_raw_sum = np.sum(confusion_matrix, axis=1)\n",
    "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
    "    average_acc = np.mean(each_acc)\n",
    "    return each_acc, average_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 427165,
     "status": "ok",
     "timestamp": 1602478831124,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "Jw2j7mjQkkEC"
   },
   "outputs": [],
   "source": [
    "def reports (X_test,y_test,name):\n",
    "    #start = time.time()\n",
    "    Y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    #end = time.time()\n",
    "    #print(end - start)\n",
    "    if name == 'IP':\n",
    "        target_names = ['Alfalfa', 'Corn-notill', 'Corn-mintill', 'Corn'\n",
    "                        ,'Grass-pasture', 'Grass-trees', 'Grass-pasture-mowed', \n",
    "                        'Hay-windrowed', 'Oats', 'Soybean-notill', 'Soybean-mintill',\n",
    "                        'Soybean-clean', 'Wheat', 'Woods', 'Buildings-Grass-Trees-Drives',\n",
    "                        'Stone-Steel-Towers']\n",
    "    elif name == 'SA':\n",
    "        target_names = ['Brocoli_green_weeds_1','Brocoli_green_weeds_2','Fallow','Fallow_rough_plow','Fallow_smooth',\n",
    "                        'Stubble','Celery','Grapes_untrained','Soil_vinyard_develop','Corn_senesced_green_weeds',\n",
    "                        'Lettuce_romaine_4wk','Lettuce_romaine_5wk','Lettuce_romaine_6wk','Lettuce_romaine_7wk',\n",
    "                        'Vinyard_untrained','Vinyard_vertical_trellis']\n",
    "    elif name == 'PU':\n",
    "        target_names = ['Asphalt','Meadows','Gravel','Trees', 'Painted metal sheets','Bare Soil','Bitumen',\n",
    "                        'Self-Blocking Bricks','Shadows']\n",
    "    \n",
    "    classification = classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names)\n",
    "    oa = accuracy_score(np.argmax(y_test, axis=1), y_pred)\n",
    "    confusion = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
    "    each_acc, aa = AA_andEachClassAccuracy(confusion)\n",
    "    kappa = cohen_kappa_score(np.argmax(y_test, axis=1), y_pred)\n",
    "    score = model.evaluate(X_test, y_test, batch_size=32)\n",
    "    Test_Loss =  score[0]*100\n",
    "    Test_accuracy = score[1]*100\n",
    "    \n",
    "    return classification, confusion, Test_Loss, Test_accuracy, oa*100, each_acc*100, aa*100, kappa*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 445851,
     "status": "ok",
     "timestamp": 1602478849818,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "wiez8wEtkkEE",
    "outputId": "9955427d-ee60-4060-b1eb-9e79bbf5b67f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 9s 35ms/step - loss: 0.2537 - accuracy: 0.9996\n"
     ]
    }
   ],
   "source": [
    "classification, confusion, Test_loss, Test_accuracy, oa, each_acc, aa, kappa = reports(Xtest,ytest,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 445840,
     "status": "ok",
     "timestamp": 1602478849819,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "kR-idaI8J5bl"
   },
   "outputs": [],
   "source": [
    "classification = str(classification)\n",
    "confusion = str(confusion)\n",
    "file_name = \"classification_report_SA.txt\"\n",
    "\n",
    "with open(file_name, 'w') as x_file:\n",
    "    x_file.write('{} Test loss (%)'.format(Test_loss))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Test accuracy (%)'.format(Test_accuracy))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Kappa accuracy (%)'.format(kappa))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Overall accuracy (%)'.format(oa))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Average accuracy (%)'.format(aa))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{}'.format(classification))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{}'.format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 445833,
     "status": "ok",
     "timestamp": 1602478849820,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "xGcIixswkkEG"
   },
   "outputs": [],
   "source": [
    "def Patch(data,height_index,width_index):\n",
    "    height_slice = slice(height_index, height_index+PATCH_SIZE)\n",
    "    width_slice = slice(width_index, width_index+PATCH_SIZE)\n",
    "    patch = data[height_slice, width_slice, :]\n",
    "    \n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 445826,
     "status": "ok",
     "timestamp": 1602478849821,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "r-HdxMrCkkEJ"
   },
   "outputs": [],
   "source": [
    "# load the original image\n",
    "X, y = loadData(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 445812,
     "status": "ok",
     "timestamp": 1602478849821,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "6GaaBm4BkkEL"
   },
   "outputs": [],
   "source": [
    "height = y.shape[0]\n",
    "width = y.shape[1]\n",
    "PATCH_SIZE = windowSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 470026,
     "status": "ok",
     "timestamp": 1602478874044,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "oumhazm3kkEN"
   },
   "outputs": [],
   "source": [
    "K = 3\n",
    "X,fa = applyFA(X, numComponents=K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 470018,
     "status": "ok",
     "timestamp": 1602478874046,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "tvZuH_0-kkEP"
   },
   "outputs": [],
   "source": [
    "X = padWithZeros(X, PATCH_SIZE//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "4sHtc-12kkER"
   },
   "outputs": [],
   "source": [
    "# calculate the predicted image\n",
    "outputs = np.zeros((height,width))\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        target = int(y[i,j])\n",
    "        if target == 0 :\n",
    "            continue\n",
    "        else :\n",
    "            image_patch=Patch(X,i,j)\n",
    "            X_test_image = image_patch.reshape(1,image_patch.shape[0],image_patch.shape[1], image_patch.shape[2], 1).astype('float32')                                   \n",
    "            prediction = (model.predict(X_test_image))\n",
    "            prediction = np.argmax(prediction, axis=1)\n",
    "            outputs[i][j] = prediction+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "vBPvnosekkEZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spectral.save_rgb(\"predictions_SA.jpg\", outputs.astype(int), colors=spectral.spy_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "KpnGO-c_kkET",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/condashare/tf/lib/python3.8/site-packages/spectral/graphics/spypylab.py:796: UserWarning:\n",
      "\n",
      "Failed to create RectangleSelector object. Interactive pixel class labeling will be unavailable.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ground_truth = spectral.imshow(classes = y,figsize =(7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "5yIVQ8-hkkEW",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_image = spectral.imshow(classes = outputs.astype(int),figsize =(7,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JL4rV6j7kkEa"
   },
   "source": [
    "spectral.save_rgb(str(dataset)+\"_ground_truth.jpg\", y, colors=spectral.spy_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN/aVtrq8w9XQ9tKxeZX/5h",
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
